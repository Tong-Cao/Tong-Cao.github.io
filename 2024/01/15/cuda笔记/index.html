<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Tong">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
        
            <link rel="preconnect" href="https://npm.elemecdn.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2024/01/15/cuda笔记/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="CUDA代码基本结构1234567891011121314# include&lt;stdio.h&gt;&#x2F;&#x2F; __global__为核函数标志__global__ void hello(){    printf(&quot;hello world from GPU\n&quot;);}&#x2F;&#x2F; 主机代码 在cpu运行main函数int main(){    hello&lt;&lt;&lt;1,10&gt;&gt;&amp;g">
<meta property="og:type" content="article">
<meta property="og:title" content="cuda笔记">
<meta property="og:url" content="http://example.com/2024/01/15/cuda%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="CUDA代码基本结构1234567891011121314# include&lt;stdio.h&gt;&#x2F;&#x2F; __global__为核函数标志__global__ void hello(){    printf(&quot;hello world from GPU\n&quot;);}&#x2F;&#x2F; 主机代码 在cpu运行main函数int main(){    hello&lt;&lt;&lt;1,10&gt;&gt;&amp;g">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/cuda1.png">
<meta property="og:image" content="http://example.com/images/cuda2.png">
<meta property="og:image" content="http://example.com/images/cuda3.png">
<meta property="og:image" content="http://example.com/images/cuda4.png">
<meta property="article:published_time" content="2024-01-15T07:03:12.000Z">
<meta property="article:modified_time" content="2024-08-15T06:48:01.016Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="cuda">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/cuda1.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/nezha.webp" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/nezha.webp">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/nezha.webp">
    <!--- Page Info-->
    
    <title>
        
            cuda笔记 -
        
        Tong&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/assets/fonts.css">
    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.xml"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[""]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/test2.jpg","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"Tong's Blog","subtitle":{"text":["不管怎样，别忘了热爱生活就好"],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":false,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/Tong-Cao","instagram":null,"zhihu":null,"twitter":null,"email":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.1.3","navbar":{"categories":{"Categories":{"icon":"fa-solid fa-folder","path":"/categories/"}},"tags":{"Tags":{"icon":"fa-solid fa-tags","path":"/tags/"}},"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"cloud"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":null},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}}};
    Global.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Tong&#39;s Blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">cuda笔记</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/nezha.webp">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Tong</span>
                            
                                <span class="author-label"></span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2024-01-15 15:03:12</span>
        <span class="mobile">2024-01-15 15:03</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2024-08-15 14:48:01</span>
            <span class="mobile">2024-08-15 14:48</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/cuda/">cuda</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h1><h2 id="代码基本结构"><a href="#代码基本结构" class="headerlink" title="代码基本结构"></a><strong>代码基本结构</strong></h2><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// __global__为核函数标志</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">hello</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello world from GPU\n"</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 主机代码 在cpu运行main函数</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    hello&lt;&lt;&lt;<span class="number">1</span>,<span class="number">10</span>&gt;&gt;&gt;();<span class="comment">//在GPU中运行核函数 &lt;&lt;&lt;1,10&gt;&gt;&gt;指定1个线程块 每个块中10个线程 </span></span><br><span class="line">    <span class="comment">// 这里会在10个线程中运行hello函数  输出结果为10行"hello world from GPU"</span></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();<span class="comment">// 用于cpu和GPU同步 这里main函数会等待上面核函数运行完成后再往下运行</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello world from CPU\n"</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p><strong>运行</strong></p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvcc test.cu -o <span class="built_in">test</span> <span class="comment">#使用nvcc编译test.cu文件 输出可执行文件test</span></span><br><span class="line">./test  <span class="comment">#运行可执行文件test</span></span><br></pre></td></tr></table></figure></div>

<p><strong>同步函数</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaDeviceSynchronize</span>();<span class="comment">// main函数中 等待上一个的GPU核函数运行完成后 再接着</span></span><br><span class="line"></span><br><span class="line">__syncthreads(); <span class="comment">//同步一个block中的线程 其他block中的线程无法同步</span></span><br></pre></td></tr></table></figure></div>

<p><strong>内存分配及数值传递函数</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> iElemCount = <span class="number">512</span>;                               <span class="comment">// 设置矩阵元素数量</span></span><br><span class="line"><span class="type">size_t</span> stBytesCount = iElemCount * <span class="built_in">sizeof</span>(<span class="type">float</span>);   <span class="comment">// 字节数 size_t是一种无符号整数类型常被用来表示对象的大小或者索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// cpu申请内存</span></span><br><span class="line"><span class="type">float</span> *fpHost_A;</span><br><span class="line">fpHost_A = (<span class="type">float</span> *)<span class="built_in">malloc</span>(stBytesCount);<span class="comment">//为矩阵A分配主机内存</span></span><br><span class="line"><span class="built_in">memset</span>(fpHost_A, <span class="number">0</span>, stBytesCount);  <span class="comment">// 主机内存初始化为0 参数1：指针 参数2：初始化的值 参数3：字节数</span></span><br><span class="line"><span class="built_in">free</span>(fpHost_A);<span class="comment">//释放内存</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//GPU申请内存</span></span><br><span class="line"><span class="type">float</span> *fpDevice_A;</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;fpDevice_A, stBytesCount);<span class="comment">//为矩阵A分配设备内存 第一个参数为指向指针的指针 相当于cpu中的malloc</span></span><br><span class="line"><span class="built_in">cudaMemset</span>(fpDevice_A, <span class="number">0</span>, stBytesCount);  <span class="comment">// 设备内存初始化为0</span></span><br><span class="line"><span class="built_in">cudaFree</span>(fpDevice_A);<span class="comment">//释放GPU内存</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//数据传递 (目标内存区域的指针，源内存区域的指针，要复制的字节数，复制的方向)</span></span><br><span class="line"><span class="built_in">cudaMemcpy</span>(fpDevice_A, fpHost_A, stBytesCount, cudaMemcpyHostToDevice); </span><br></pre></td></tr></table></figure></div>



<h2 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h2><ul>
<li><p>每个核函数产生的所有线程在同一个<strong>网格（grid）</strong>中</p>
</li>
<li><p>指定配置&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;   <strong>grid_size</strong>是指一个核函数的grid中有多少个线程块(block)  <strong>block_size</strong>是指每个block中有多少的<strong>线程(thread）</strong></p>
</li>
<li><p><strong>gridDim.x</strong>  : 即grid_size的大小，即线程块的数量（一维的情况下）</p>
</li>
<li><p><strong>blockIdx.x</strong> : 每个线程块的索引值（从<strong>0</strong>到<strong>gridDim.x减1</strong>）</p>
</li>
<li><p><strong>blockDim.x</strong> : block的维度，即block_size的大小，即block中线程数量</p>
</li>
<li><p><strong>threadIdx.x</strong> ：每个线程的索引值（从<strong>0</strong>到<strong>blockDim.x减1</strong>）</p>
</li>
<li><p>grid_size, block_size可以设置为二维、三维。一般定义为<strong>dim3</strong>类型的变量</p>
</li>
<li><p>定义一维 <strong>dim3</strong> grid_siez(128); <strong>dim3</strong> block_size(256);</p>
</li>
<li><p>定义二维 <strong>dim3</strong> grid_siez(2,2); <strong>dim3</strong> block_size(1,2);</p>
</li>
<li><p><strong>注意</strong>：在二维情况下，<strong>dim3</strong> block_size(1,2) ，代表<strong>两行一列</strong>与通常矩阵表示相反，threadIdx.x实际上代表的是第几列，threadIdx.y代表的是第几行。</p>
</li>
</ul>
<p>查看当前设备支持的最大线程块和线程数量：</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    <span class="type">int</span> device;</span><br><span class="line">    <span class="built_in">cudaGetDevice</span>(&amp;device);  <span class="comment">// get current device</span></span><br><span class="line">    <span class="built_in">cudaGetDeviceProperties</span>(&amp;prop, device);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">"Max threads per block: "</span> &lt;&lt; prop.maxThreadsPerBlock &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">"Max block dimensions: "</span> &lt;&lt; prop.maxThreadsDim[<span class="number">0</span>] &lt;&lt; <span class="string">" x "</span> </span><br><span class="line">              &lt;&lt; prop.maxThreadsDim[<span class="number">1</span>] &lt;&lt; <span class="string">" x "</span> &lt;&lt; prop.maxThreadsDim[<span class="number">2</span>] &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">"Max grid dimensions: "</span> &lt;&lt; prop.maxGridSize[<span class="number">0</span>] &lt;&lt; <span class="string">" x "</span> </span><br><span class="line">              &lt;&lt; prop.maxGridSize[<span class="number">1</span>] &lt;&lt; <span class="string">" x "</span> &lt;&lt; prop.maxGridSize[<span class="number">2</span>] &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>





<h2 id="CUDA执行模型"><a href="#CUDA执行模型" class="headerlink" title="CUDA执行模型"></a>CUDA执行模型</h2><h3 id="SM"><a href="#SM" class="headerlink" title="SM"></a><strong>SM</strong></h3><p>GPU架构就是由可扩展的流式多处理器（Streaming Multiprocessors简称SM）阵列所构建，整个硬件的并行就是不断复制这种架构实现的。通常每个GPU都有多个SM，每个SM都支持上百个线程的并行，所以GPU可以支持上千个线程的并行。</p>
<p><strong>每一个block会被分配到不同的SM上</strong></p>
<h3 id="Cuda-Core"><a href="#Cuda-Core" class="headerlink" title="Cuda Core"></a><strong>Cuda Core</strong></h3><p>核心，也可以叫<strong>SP</strong>(Streaming processors)，最小的执行单元。</p>
<p><strong>每一个thread对应一个CUDA Core</strong></p>
<h3 id="wrap"><a href="#wrap" class="headerlink" title="wrap"></a><strong>wrap</strong></h3><p><strong>线程束</strong>，32个线程组成一个warp，每一个warp执行相同的命令。SM 采用的 SIMT (Single-Instruction, Multiple-Thread，单指令多线程) 架构，<strong>warp (线程束) 是最基本的执行单元</strong>。一个 warp 包含32个并行 thread，这些 thread 以不同数据资源执行相同的指令。一个 warp 只包含一条指令，所以：<strong>warp 本质上是线程在 GPU 上运行的最小单元。</strong></p>
<p>由于warp的大小为32，所以block所含的thread的大小一般要设置为<strong>32的倍数</strong>。</p>
<h3 id="SM并行运算"><a href="#SM并行运算" class="headerlink" title="SM并行运算"></a><strong>SM并行运算</strong></h3><p>每个kernel调用都会起一个Grid，Grid中有很多<strong>线程块</strong>，每个Block都会被分配到可用的SM上执行（不能重绑），<strong>Block中的线程会被划分为多个Warp用以调度运行</strong>，SM内部通过两个Warp调度器和两个指令分发单元实现warps的调度，同一时刻，会并发运行两个warp，每个warp会被分发到一个Cuda Core Group(16个CUDA Core), 或者16个load/store单元，或者4个SFU上去真正执行，且<strong>每次分发只执行一条指令</strong>，在Fermi架构中每个SM可以同时处理48个warp。</p>
<p><strong>软件抽象和硬件对应关系：</strong></p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/cuda1.png" alt="cuda1"></p>
<h2 id="CUDA内存"><a href="#CUDA内存" class="headerlink" title="CUDA内存"></a>CUDA内存</h2><h3 id="register"><a href="#register" class="headerlink" title="register"></a><strong>register</strong></h3><p>寄存器，不同core彼此独立。寄存器内存存在于芯片上（on-chip），是GPU上运行速度最快的内存。</p>
<p>在核函数中声明的一个<strong>没有其他修饰符的变量</strong>，通常存储在寄存器中。在核函数中声明的数组中，如果用于引用该数组的索引是常量，且能在编译时确定，那么数组也存储在寄存器中。此外，各种内建变量，如gridDim、blockDim、blockIdx、threadIdx以及warpSize都保存在特殊的寄存器中。</p>
<h3 id="local-memory"><a href="#local-memory" class="headerlink" title="local memory"></a><strong>local memory</strong></h3><p>局部内存，不同core彼此独立。</p>
<p>每个线程除了分配的寄存器外，还有独立的存储空间，即局部内存。局部内存是私有的，只有本线程才能进行读写访问。编译器可能放到局部内存的变量有:</p>
<p>（1） 线程使用的寄存器过多而没有足够的寄存器来存储变量，如使用了大型的局部数据结构；</p>
<p>（2） 编译器无法静态地确定数据的大小。</p>
<h3 id="shared-memory"><a href="#shared-memory" class="headerlink" title="shared memory"></a><strong>shared memory</strong></h3><p>共享内存，可以被SM中的所有core访问。</p>
<p>共享内存主要作用有两个: 一个是减少核函数对全局内存的访问次数，实现高效的线程块内部通信；另一个是提高全局内存访问的合并度。</p>
<p>在核函数中，使用**__ shared__**修饰的变量存放在共享内存中。因为共享内存是片上内存，所以与全局内存和局部内存相比，具有更高的带宽和更低的延迟。</p>
<p>共享内存是线程之间通信的基本方式，一个块内的线程通过使用共享内存可以相互合作。使用**__syncthreads()**可以同步线程块中的线程。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//静态共享内存：在核函数中声明，需要指定其大小。</span></span><br><span class="line">__shared__ <span class="type">float</span> s_y[<span class="number">128</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">//动态共享内存</span></span><br><span class="line">kernal&lt;&lt;&lt;grid_size, block_size, <span class="built_in">sizeof</span>(<span class="type">float</span>) * block_size&gt;&gt;&gt;();</span><br><span class="line"><span class="comment">//前面2个参数网格大小和线程块大小，第三个参数就是核函数中每个线程块需要 定义的动态共享内存的字节数</span></span><br><span class="line"><span class="comment">//核函数中的动态声明</span></span><br><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">float</span> s_y[];</span><br></pre></td></tr></table></figure></div>



<h3 id="global-memory"><a href="#global-memory" class="headerlink" title="global memory"></a><strong>global memory</strong></h3><p>全局内存，所有SM中的core都可以访问。</p>
<p><strong>动态全局变量</strong>：使用cudaMalloc()分配全局内存，使用cudaFree()释放全局内存。</p>
<p>静态全局变量：使用**__ device__**修饰符静态声明一个全局变量。要在host和核函数之外声明，host和device都可以对其进行读写。</p>
<h3 id="const-memory"><a href="#const-memory" class="headerlink" title="const memory"></a><strong>const memory</strong></h3><p>常量内存是片外内存。在 CUDA 中，常量内存是一种特殊类型的只读内存，它被所有线程块共享。常量内存的大小有限（在大多数设备上为 64KB），但访问速度非常快，特别是当所有线程访问同一常量时。</p>
<p>在CUDA中，常量变量必须在全局空间中声明，不能在核函数中声明，使用**__ constant__**修饰，在CPU上有cudaMemcpyToSymbol()初始化，不需要进行空间释放。</p>
<p>线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。数学公式中的系数是一个很好使用常量内存的例子。因为每从一个常量内存中读取一次数据，都会广播给线程束里的所有线程。另外一个例子，核函数的参数const int N是在主机端定义的变量，并通过传值的方式传给核函数的线程使用。在核函数代码段中，if （n &lt; N）中，这个参数N就被每一个线程使用。核函数中的每一个线程都知道该变量的值，而且对它的访问比全局内存要快很多。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//声明一个常量内存</span></span><br><span class="line">__constant__ <span class="type">float</span> constData[<span class="number">256</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="comment">// 初始化 data 数组...</span></span><br><span class="line">    <span class="type">float</span> data[<span class="number">256</span>];</span><br><span class="line">    <span class="comment">// 将data数据赋值给constData</span></span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(constData, data, <span class="built_in">sizeof</span>(data));</span><br><span class="line">    </span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="纹理内存"><a href="#纹理内存" class="headerlink" title="纹理内存"></a><strong>纹理内存</strong></h3><p>纹理内存类似于常量缓存，也是一种具有缓存的全局内存，与常量内存具有相同的生命周期和作用范围。纹理内存通常比常量内存要大，适合实现图像处理和查找表等操作。</p>
<h3 id="GPU缓存"><a href="#GPU缓存" class="headerlink" title="GPU缓存"></a><strong>GPU缓存</strong></h3><p>在GPU上有四种缓存: 一级缓存、二级缓存、只读常量缓存、只读纹理缓存。</p>
<p>每个SM都有一级缓存，所有SM共享一个二级缓存。</p>
<h2 id="bank-conflict"><a href="#bank-conflict" class="headerlink" title="bank conflict"></a><strong>bank conflict</strong></h2><p>为了获得较高的内存带宽，共享存储器被划分为多个大小相等的存储器模块，称为bank，可以被同时访问。一般将shared memory 划分成32个bank对应一个线程束中的32个线程。</p>
<p><strong>每个存储体（bank）每个周期只能指向一次操作。</strong></p>
<p>我们将数据A[0]~ A[31]分别存在<strong>bank0~bank31</strong> ，当我们使用32个线程分别去访问 A[0]~A[31]时可以在一个周期中同时读取。</p>
<p>但当我们将A[0]~ A[31]全部存在bank0中，此时32个线程去访问A[0]~A[31]则需要32个周期<strong>（每个存储体（bank）每个周期只能指向一次操作）</strong>，此时就发生了bank conflict。</p>
<p><strong>bank conflict</strong>：当一个warp中的不同线程访问一个bank中的<strong>不同的</strong>字地址时，就会发生bank冲突。（不同线程访问同一个bank的同一个字地址时不会发生bank conflict）</p>
<p><strong>解决办法：</strong></p>
<p> padding：原数据中最后加入一列。</p>
<p> <a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/436395393?utm_id=0">参考 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h2 id="性能评价"><a href="#性能评价" class="headerlink" title="性能评价"></a>性能评价</h2><p><strong>nvprof</strong> </p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof ./执行二进制文件</span><br></pre></td></tr></table></figure></div>

<p><strong>cuda计时</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//CUDA事件计时</span></span><br><span class="line">cudaEvent_t start, stop;<span class="comment">//CUDA事件</span></span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;start);<span class="comment">//创建CUDA事件</span></span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;stop);<span class="comment">//创建CUDA事件</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(start);<span class="comment">//记录CUDA事件</span></span><br><span class="line">kernal&lt;&lt;&lt;&gt;&gt;&gt;();<span class="comment">//执行CUDA核函数</span></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stop);<span class="comment">//记录CUDA事件</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaEventSynchronize</span>(stop);<span class="comment">//同步CUDA事件</span></span><br><span class="line"><span class="type">float</span> milliseconds = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">cudaEventElapsedTime</span>(&amp;milliseconds, start, stop);<span class="comment">//计算CUDA事件的时间间隔</span></span><br><span class="line">cout &lt;&lt; <span class="string">"GPU time: "</span> &lt;&lt; milliseconds &lt;&lt; <span class="string">"ms"</span> &lt;&lt; endl;</span><br><span class="line"><span class="comment">//销毁CUDA事件</span></span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(stop);</span><br></pre></td></tr></table></figure></div>



<h2 id="矩阵加法"><a href="#矩阵加法" class="headerlink" title="矩阵加法"></a>矩阵加法</h2><p><strong>设置GPU</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="comment">// 检测计算机GPU数量</span></span><br><span class="line">    <span class="type">int</span> iDeviceCount = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//cudaError_t是cuda的错误类型 </span></span><br><span class="line">    cudaError_t error = <span class="built_in">cudaGetDeviceCount</span>(&amp;iDeviceCount);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 当返回值error不为cudaSuccess时，说明没有找到CUDA兼容的GPU</span></span><br><span class="line">    <span class="keyword">if</span> (error != cudaSuccess || iDeviceCount == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"No CUDA campatable GPU found!\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"The count of GPUs is %d.\n"</span>, iDeviceCount);</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 设置执行</span></span><br><span class="line">    <span class="type">int</span> iDev = <span class="number">0</span>;</span><br><span class="line">    error = <span class="built_in">cudaSetDevice</span>(iDev);<span class="comment">//设置使用GPU 0  </span></span><br><span class="line">    <span class="comment">// 返回值为cudaSuccess说明设置成功，否则设置失败</span></span><br><span class="line">    <span class="keyword">if</span> (error != cudaSuccess)</span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"fail to set GPU 0 for computing.\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"set GPU 0 for computing.\n"</span>);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<p><strong>矩阵加法</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"common.cuh"</span><span class="comment">// 包含setGPU()函数</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 核函数，计算矩阵和</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">addFromGPU</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;<span class="comment">// 内置变量，表示当前线程所在的块的索引</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;<span class="comment">// 内置变量，表示当前线程所在的线程块中的索引</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> id = tid + bid * blockDim.x; <span class="comment">//blockDim.x为线程块中线程的数量，id表示当前线程的索引</span></span><br><span class="line">    <span class="comment">// 一共有blockDim.x * gridDim.x个线程，每个线程计算一个元素</span></span><br><span class="line">    <span class="comment">// blockIdx.x和blockDim.x是内置变量，分别表示当前线程所在的块的索引和块中线程的数量</span></span><br><span class="line">    <span class="comment">// 所以每个线程会只计算一个元素，id表示当前线程计算的元素的索引</span></span><br><span class="line">    C[id] = A[id] + B[id];</span><br><span class="line">    </span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用随机数初始化矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initialData</span><span class="params">(<span class="type">float</span> *addr, <span class="type">int</span> elemCount)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; elemCount; i++)</span><br><span class="line">    {</span><br><span class="line">        addr[i] = (<span class="type">float</span>)(<span class="built_in">rand</span>() &amp; <span class="number">0xFF</span>) / <span class="number">10.f</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="comment">// 1、从common.cuh中调用setGPU函数，选择设备</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2、分配主机内存和设备内存，并初始化</span></span><br><span class="line">    <span class="type">int</span> iElemCount = <span class="number">512</span>;                               <span class="comment">// 设置矩阵元素数量</span></span><br><span class="line">    <span class="type">size_t</span> stBytesCount = iElemCount * <span class="built_in">sizeof</span>(<span class="type">float</span>);   <span class="comment">// 字节数 size_t是一种无符号整数类型常被用来表示对象的大小或者索引</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// （1）分配主机内存，并初始化</span></span><br><span class="line">    <span class="type">float</span> *fpHost_A, *fpHost_B, *fpHost_C;</span><br><span class="line">    fpHost_A = (<span class="type">float</span> *)<span class="built_in">malloc</span>(stBytesCount);<span class="comment">//为矩阵A分配主机内存</span></span><br><span class="line">    fpHost_B = (<span class="type">float</span> *)<span class="built_in">malloc</span>(stBytesCount);</span><br><span class="line">    fpHost_C = (<span class="type">float</span> *)<span class="built_in">malloc</span>(stBytesCount);</span><br><span class="line">    <span class="comment">// 当三个指针都不为空时，初始化为0</span></span><br><span class="line">    <span class="keyword">if</span> (fpHost_A != <span class="literal">NULL</span> &amp;&amp; fpHost_B != <span class="literal">NULL</span> &amp;&amp; fpHost_C != <span class="literal">NULL</span>)</span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">memset</span>(fpHost_A, <span class="number">0</span>, stBytesCount);  <span class="comment">// 主机内存初始化为0 参数1：指针 参数2：初始化的值 参数3：字节数</span></span><br><span class="line">        <span class="built_in">memset</span>(fpHost_B, <span class="number">0</span>, stBytesCount);</span><br><span class="line">        <span class="built_in">memset</span>(fpHost_C, <span class="number">0</span>, stBytesCount);</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Fail to allocate host memory!\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// （2）分配设备内存，并初始化</span></span><br><span class="line">    <span class="type">float</span> *fpDevice_A, *fpDevice_B, *fpDevice_C;</span><br><span class="line">    <span class="comment">// cudaMalloc((float**)&amp;fpDevice_A, stBytesCount);//为矩阵A分配设备内存 相当于cpu中的malloc</span></span><br><span class="line">    <span class="comment">// cudaMalloc((float**)&amp;fpDevice_B, stBytesCount);</span></span><br><span class="line">    <span class="comment">// cudaMalloc((float**)&amp;fpDevice_C, stBytesCount);</span></span><br><span class="line">    <span class="built_in">cudaMalloc</span>(&amp;fpDevice_A, stBytesCount);<span class="comment">//为矩阵A分配设备内存 相当于cpu中的malloc</span></span><br><span class="line">    <span class="built_in">cudaMalloc</span>(&amp;fpDevice_B, stBytesCount);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>(&amp;fpDevice_C, stBytesCount);</span><br><span class="line">    <span class="keyword">if</span> (fpDevice_A != <span class="literal">NULL</span> &amp;&amp; fpDevice_B != <span class="literal">NULL</span> &amp;&amp; fpDevice_C != <span class="literal">NULL</span>)</span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">cudaMemset</span>(fpDevice_A, <span class="number">0</span>, stBytesCount);  <span class="comment">// 设备内存初始化为0</span></span><br><span class="line">        <span class="built_in">cudaMemset</span>(fpDevice_B, <span class="number">0</span>, stBytesCount);</span><br><span class="line">        <span class="built_in">cudaMemset</span>(fpDevice_C, <span class="number">0</span>, stBytesCount);</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"fail to allocate memory\n"</span>);</span><br><span class="line">        <span class="built_in">free</span>(fpHost_A);</span><br><span class="line">        <span class="built_in">free</span>(fpHost_B);</span><br><span class="line">        <span class="built_in">free</span>(fpHost_C);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3、初始化主机中数据</span></span><br><span class="line">    <span class="built_in">srand</span>(<span class="number">666</span>); <span class="comment">// 设置随机种子</span></span><br><span class="line">    <span class="built_in">initialData</span>(fpHost_A, iElemCount);</span><br><span class="line">    <span class="built_in">initialData</span>(fpHost_B, iElemCount);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 4、数据从主机复制到设备</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(fpDevice_A, fpHost_A, stBytesCount, cudaMemcpyHostToDevice); </span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(fpDevice_B, fpHost_B, stBytesCount, cudaMemcpyHostToDevice); </span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(fpDevice_C, fpHost_C, stBytesCount, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5、调用核函数在设备中进行计算</span></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(iElemCount / <span class="number">32</span>)</span></span>; <span class="comment">//一共有 32*(iElemCount / 32) = iElemCount个线程</span></span><br><span class="line"></span><br><span class="line">    addFromGPU&lt;&lt;&lt;grid, block&gt;&gt;&gt;(fpDevice_A, fpDevice_B, fpDevice_C, iElemCount);    <span class="comment">// 调用核函数</span></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>(); <span class="comment">// 同步，等待核函数执行完毕</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6、将计算得到的数据从设备传给主机</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(fpHost_C, fpDevice_C, stBytesCount, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)    <span class="comment">// 打印</span></span><br><span class="line">    {</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"idx=%2d\tmatrix_A:%.2f\tmatrix_B:%.2f\tresult=%.2f\n"</span>, i+<span class="number">1</span>, fpHost_A[i], fpHost_B[i], fpHost_C[i]);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 7、释放主机与设备内存</span></span><br><span class="line">    <span class="built_in">free</span>(fpHost_A);</span><br><span class="line">    <span class="built_in">free</span>(fpHost_B);</span><br><span class="line">    <span class="built_in">free</span>(fpHost_C);</span><br><span class="line">    <span class="built_in">cudaFree</span>(fpDevice_A);</span><br><span class="line">    <span class="built_in">cudaFree</span>(fpDevice_B);</span><br><span class="line">    <span class="built_in">cudaFree</span>(fpDevice_C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h2 id="规约算法"><a href="#规约算法" class="headerlink" title="规约算法"></a>规约算法</h2><p>对A[0]~A[15]计算总和。</p>
<p><strong>参考: <a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/426978026">链接1 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 、<a class="link" target="_blank" rel="noopener" href="https://www.cnblogs.com/5long/p/algorithms-on-cuda-reduction.html">链接2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></p>
<h3 id="一、线程不连续规约"><a href="#一、线程不连续规约" class="headerlink" title="一、线程不连续规约"></a>一、线程不连续规约</h3><p>使用16个线程，每个线程访问对应A中数据，再将其与后一个数据相加，不断迭代。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/cuda2.png" alt="cuda2"></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">reduction1函数 </span></span><br><span class="line"><span class="comment">float *A: 输入数组</span></span><br><span class="line"><span class="comment">int N: 数组长度      </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction_1</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动态共享内存 用于存储block内的数据 大小为线程数</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> smem[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到共享内存  每个block中都有一个smem 这里使用id和tid来对应将A中的数据按顺序存储到各个smem中</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        smem[tid] = A[global_id];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        smem[tid] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduction操作</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> stride = <span class="number">1</span>; stride &lt; blockDim.x; stride *= <span class="number">2</span>){</span><br><span class="line">        <span class="keyword">if</span>(tid % (<span class="number">2</span>*stride) == <span class="number">0</span>){</span><br><span class="line">            smem[tid] += smem[tid + stride];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = smem[<span class="number">0</span>];<span class="comment">//将结果存放在A[0]、A[1]、A[2]...中</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>这里的warp中的线程会根据if条件语句造成分化，会先执行warp中满足if的线程，再继续执行剩下的线程。</p>
<h3 id="二、线程连续规约"><a href="#二、线程连续规约" class="headerlink" title="二、线程连续规约"></a>二、<strong>线程连续规约</strong></h3><p>使用8个连续的线程，处理数据（此时线程id和数组的索引不相同，为二倍关系）</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/cuda3.png" alt="cuda2"></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">reduction2函数 </span></span><br><span class="line"><span class="comment">float *A: 输入数组</span></span><br><span class="line"><span class="comment">int N: 数组长度      </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction_2</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动态共享内存 用于存储block内的数据 大小为线程数</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> smem[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到共享内存  每个block中都有一个smem 这里使用id和tid来对应将A中的数据按顺序存储到各个smem中</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        smem[tid] = A[global_id];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        smem[tid] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduction操作</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> stride = <span class="number">1</span>; stride &lt; <span class="number">256</span>; stride *= <span class="number">2</span>){</span><br><span class="line">        <span class="type">int</span> index = <span class="number">2</span>*stride*tid;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">256</span>){</span><br><span class="line">            smem[index] += smem[index + stride];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = smem[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>此时的线程为连续的，使用相同的线程，前一半的线程集中在一个warp调度中一起执行加法，剩余线程不做任何计算。这里也可以只使用一半的线程，但是要注意修改代码中的复制到共享内存还有一些细节需要修改。</p>
<p>这里的访问的内存并不连续，有可能出现在一个warp中的两个线程访问到同一个bank造成bank冲突。</p>
<h3 id="三、线程连续、内存连续"><a href="#三、线程连续、内存连续" class="headerlink" title="三、线程连续、内存连续"></a>三、线程连续、内存连续</h3><p>让同一个warp中的线程处理连续的数据，避免出现bank冲突。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/cuda4.png" alt="cuda2"></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">reduction3函数 </span></span><br><span class="line"><span class="comment">float *A: 输入数组</span></span><br><span class="line"><span class="comment">int N: 数组长度      </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction_3</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动态共享内存 用于存储block内的数据 大小为线程数</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> smem[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到共享内存  每个block中都有一个smem 这里使用id和tid来对应将A中的数据按顺序存储到各个smem中</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        smem[tid] = A[global_id];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        smem[tid] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduction操作</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> stride = blockDim.x/<span class="number">2</span>; stride &gt; <span class="number">0</span>; stride /= <span class="number">2</span>){</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; stride){</span><br><span class="line">            smem[tid] += smem[tid + stride];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = smem[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>此时线程1-7 在访问partialSum[t]时，为连续数据，接着访问partialSum[t + stride]也是连续的数据，可以避免出现bank冲突。</p>
<h3 id="四、减半block"><a href="#四、减半block" class="headerlink" title="四、减半block"></a>四、减半block</h3><p>上面的方法中，在第一轮的迭代中，我们都只使用了前一半的线程，后一半的线程处理将数据移动到shared memory没有做其他操作。我们可以通过在复制数据时同时做一次加法，充分利用后一半的线程。</p>
<p><strong>注意</strong>：</p>
<p>我们使用smem[tid] = A[global_id] + A[global_id + blockDim.x]来多做一次加法，</p>
<p>此时每个block的线程以及处理的数组长度不变，block的数量会减小一半</p>
<p>此时global_id的索引修改为int global_id = blockIdx.x * blockDim.x * 2 + threadIdx.x;</p>
<p>同时需要<strong>手动将&lt;&lt;&lt;grid, block&gt;&gt;&gt;中的grid大小减半</strong>。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">reduction4函数 </span></span><br><span class="line"><span class="comment">float *A: 输入数组</span></span><br><span class="line"><span class="comment">int N: 数组长度   </span></span><br><span class="line"><span class="comment">global_id改为blockIdx.x*blockDim.x*2 + threadIdx.x </span></span><br><span class="line"><span class="comment">每个block中处理的数据增加一倍，block线程数不变，block总数减半</span></span><br><span class="line"><span class="comment">需要手动设置grid为原来的一半 </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction_4</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x*<span class="number">2</span> + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动态共享内存 用于存储block内的数据 大小为线程数</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> smem[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到共享内存  每个block中都有一个smem 这里使用id和tid来对应将A中的数据按顺序存储到各个smem中</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        smem[tid] = A[global_id] + A[global_id + blockDim.x];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        smem[tid] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduction操作</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> stride = blockDim.x/<span class="number">2</span>; stride &gt; <span class="number">0</span>; stride /= <span class="number">2</span>){</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; stride){</span><br><span class="line">            smem[tid] += smem[tid + stride];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = smem[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="五、减少同步"><a href="#五、减少同步" class="headerlink" title="五、减少同步"></a>五、减少同步</h3><p>当stride变成32时，此时只有32个线程会进行加法操作。这32个线程是在同一个warp中的并且执行同一条指令所以会自然保持同步，此时可以将__syncthreads();去掉。</p>
<p>所以在stride变成32后，后面可以直接进行加法操作，不需要同步。</p>
<p>不过需要注意，编写线程束同步代码时，必须对共享内存的指针使用<strong>volatile</strong>关键字修饰，否则可能会由于编译器的优化行为改变内存的操作顺序从而使结果不正确。</p>
<p><strong>volatile</strong>关键字：volatile用于声明一个变量，告诉编译器该变量值容易<strong>发生改变</strong>，在编译、读取、存储该变量的时候都<strong>不要做任何优化</strong>，因此编译后的程序每次需要存储或读取这个变量的时候，都会<strong>直接从变量地址中读取存储数据</strong>，不做优化。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">reduction5函数 </span></span><br><span class="line"><span class="comment">float *A: 输入数组</span></span><br><span class="line"><span class="comment">int N: 数组长度   </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction_5</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x*<span class="number">2</span> + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动态共享内存 用于存储block内的数据 大小为线程数</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> smem[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到共享内存  每个block中都有一个smem 这里使用id和tid来对应将A中的数据按顺序存储到各个smem中</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        smem[tid] = A[global_id] + A[global_id + blockDim.x];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        smem[tid] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduction操作</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> stride = blockDim.x/<span class="number">2</span>; stride &gt; <span class="number">32</span>; stride /= <span class="number">2</span>){</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; stride){</span><br><span class="line">            smem[tid] += smem[tid + stride];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">float</span> *wsSum = smem;<span class="comment">//使用volatile关键字防止编译器优化改变下面的顺序</span></span><br><span class="line">    <span class="keyword">if</span>(tid &lt; <span class="number">32</span>){</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">32</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">16</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">8</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">4</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">2</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">1</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = wsSum[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="六、循环完全展开"><a href="#六、循环完全展开" class="headerlink" title="六、循环完全展开"></a>六、循环完全展开</h3><p>将for循环展开，这里使用模板参数来传进blocksize。</p>
<p>使用模板传入blocksize可以让编译器在编译时确定线程块的大小，进行更多优化，比如if（blockSize &gt;= 1024）如果在编译时就知晓block为256就可以在编译时优化掉这个判断语句，提高效率。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction_6</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x*<span class="number">2</span> + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动态共享内存 用于存储block内的数据 大小为线程数</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> smem[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到共享内存  每个block中都有一个smem 这里使用id和tid来对应将A中的数据按顺序存储到各个smem中</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        smem[tid] = A[global_id] + A[global_id + blockDim.x];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        smem[tid] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduction操作</span></span><br><span class="line">    <span class="comment">// 将循环完全展开</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">1024</span>){</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">512</span>)</span><br><span class="line">            smem[tid] += smem[tid + <span class="number">512</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">512</span>){</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">256</span>)</span><br><span class="line">            smem[tid] += smem[tid + <span class="number">256</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">256</span>){</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">128</span>)</span><br><span class="line">            smem[tid] += smem[tid + <span class="number">128</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">128</span>){</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">64</span>)</span><br><span class="line">            smem[tid] += smem[tid + <span class="number">64</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">float</span> *wsSum = smem;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(tid &lt; <span class="number">32</span>){</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">32</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">16</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">8</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">4</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">2</span>];</span><br><span class="line">        wsSum[tid] += wsSum[tid + <span class="number">1</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = wsSum[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="七、shuffle操作"><a href="#七、shuffle操作" class="headerlink" title="七、shuffle操作"></a>七、shuffle操作</h3><p>shuffle函数可以在同一个warp中交换线程的寄存器值，避免通过读和写共享内存进行优化。</p>
<p><strong>float n = __shfl_down_sync(0xffffffff,sum,16)</strong>  将线程16的sum值返回到线程0 ，线程17的sum值传递回线程1…, 依次类推。</p>
<p><strong>0xffffffff</strong> 代表所有线程参与交换。</p>
<p>我们将每一个block中的线程按warp分块，每一块32个线程进行规约，再最后将所有warp块内部的总和进行规约。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">float</span> <span class="title">warpReduceSum</span><span class="params">(<span class="type">float</span> sum)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">16</span>); <span class="comment">// 0-16, 1-17, 2-18, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">8</span>);<span class="comment">// 0-8, 1-9, 2-10, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">4</span>);<span class="comment">// 0-4, 1-5, 2-6, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">2</span>);<span class="comment">// 0-2, 1-3, 4-6, 5-7, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">1</span>);<span class="comment">// 0-1, 2-3, 4-5, etc.</span></span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce7</span><span class="params">(<span class="type">float</span> *A,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="comment">//每一个thread维护一个sum</span></span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x*<span class="number">2</span> + threadIdx.x;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到sum</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){ </span><br><span class="line">        sum = A[global_id] + A[global_id + blockDim.x];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        sum = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 用来存放每一个warp的结果</span></span><br><span class="line">    <span class="type">static</span> __shared__ <span class="type">float</span> warpLevelSums[<span class="number">32</span>]; <span class="comment">//这里的warp_size为32最后使用一个warps来进行reduction操作</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> laneId = threadIdx.x % WARP_SIZE;<span class="comment">//每个warps内的线程id</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> warpId = threadIdx.x / WARP_SIZE;<span class="comment">//每个warps块的id</span></span><br><span class="line"></span><br><span class="line">    sum = <span class="built_in">warpReduceSum</span>&lt;blockSize&gt;(sum);<span class="comment">//每个warp内进行reduction操作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(laneId == <span class="number">0</span> )warpLevelSums[warpId] = sum;<span class="comment">//将每个warp的结果存放在warpLevelSums中</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用第一个warp来进行最后的规约 32个线程来读取warpLevelSums中的数据  将id大于warp块个数的summ置为0</span></span><br><span class="line">    sum = (threadIdx.x &lt; blockDim.x / WARP_SIZE) ? warpLevelSums[laneId] : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 最终的reduction操作</span></span><br><span class="line">    <span class="keyword">if</span> (warpId == <span class="number">0</span>) sum = <span class="built_in">warpReduceSum</span>&lt;blockSize/WARP_SIZE&gt;(sum);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        A[blockIdx.x] = sum;</span><br><span class="line">    } </span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="主机端main函数"><a href="#主机端main函数" class="headerlink" title="主机端main函数"></a>主机端main函数</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">//设置GPU</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 所有数赋值1 便于检查结果是否正确</span></span><br><span class="line">    <span class="type">int</span> N = <span class="number">1024</span>*<span class="number">32</span>;<span class="comment">// 数组长度</span></span><br><span class="line">    <span class="type">float</span> *h_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(N*<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++){</span><br><span class="line">        h_A[i] = <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据拷贝到GPU</span></span><br><span class="line">    <span class="type">float</span> *d_A;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_A,N*<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_A,h_A,N*<span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用kernel函数</span></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">256</span>)</span></span>;<span class="comment">// 256个线程</span></span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">((N+block.x<span class="number">-1</span>)/block.x/<span class="number">2</span>)</span></span>;<span class="comment">// grid的大小为N/block.x 向上取整 从reduction4往后手动将block数量减少一半</span></span><br><span class="line">    reduction_4&lt;&lt;&lt;grid,block,N/grid.<span class="function">x*<span class="title">sizeof</span><span class="params">(<span class="type">float</span>)</span>&gt;&gt;&gt;<span class="params">(d_A,N)</span></span>;<span class="comment">// 数组N被划分为grid.x个组，每个组中的数组大小应该为N/grid.x</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果拷贝回CPU</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(h_A,d_A,N*<span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算CPU的结果 reduction结果存放在对应的blockid的位置  比如有两个block，那么结果就存放在h_A[0]和h_A[1]中</span></span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; grid.x; i++){</span><br><span class="line">        sum += h_A[i];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印结果</span></span><br><span class="line">    std::cout&lt;&lt;<span class="string">"sum:"</span>&lt;&lt;sum&lt;&lt;std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放内存</span></span><br><span class="line">    <span class="built_in">free</span>(h_A);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_A);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>





<h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><p>使用GPU实现矩阵的乘法。</p>
<h3 id="一、直接加载"><a href="#一、直接加载" class="headerlink" title="一、直接加载"></a>一、直接加载</h3><p>矩阵A（M*K）和矩阵B（K * N）得到矩阵C（M * N）。 我们使用和矩阵C大小相同的线程，每一个线程负责计算得到对应矩阵C中的结果。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//GPU矩阵乘法</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">matrixMultiply</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> k,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y*blockDim.y + threadIdx.y;<span class="comment">//线程所在的行</span></span><br><span class="line">    <span class="type">int</span> col = blockIdx.x*blockDim.x + threadIdx.x;<span class="comment">//线程所在的列</span></span><br><span class="line">    <span class="keyword">if</span>(row &lt; m &amp;&amp; col &lt; n){</span><br><span class="line">        <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;k; i++){</span><br><span class="line">            <span class="comment">// 矩阵A的第row行的第i个元素 与 矩阵B的第i行的第col个元素 相乘</span></span><br><span class="line">            sum += array_A[row * k + i] * array_B[i * n + col];</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 保存结果到矩阵C的第row行的第col个元素</span></span><br><span class="line">        array_C[row * n + col] = sum;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="二、使用共享内存"><a href="#二、使用共享内存" class="headerlink" title="二、使用共享内存"></a>二、使用共享内存</h3><p>对于一中直接从全局内存读取A、B的值，其中C中同一行对应的线程都需要加载一次对应A中的一行值，这种重复加载以及从全局内存加载需要耗费大量时间。</p>
<p>共享内存是在同一个block中共享，假设block的大小设置为32*32，这32 *32个线程对应C中的一个32 *32的区域。 计算这32 * 32个值我们需要使用的是A中一个32 * K的子矩阵以及B中一块 K * 32 的子矩阵。</p>
<p>将A中对应的子矩阵A_sub(32 * K) 分割成 (k/32)个 大小为 （32 * 32）的块 A0、A1….</p>
<p>将B中对应的子矩阵B_sub(K * 32) 同样分割成 (k/32)个 大小为 （32 * 32）的块 B0、B1….</p>
<p>最后C中对应的位置的值可以通过 A0 * B0 + A1 * B1 + ……来得到。</p>
<p>在这个block中,A中对应的行和B中对应的列都只加载了一次，后面的小矩阵乘法都是用过共享内存加载。</p>
<p>参考：<a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43398345/article/details/130482641">链接 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">使用共享内存的矩阵乘法</span></span><br><span class="line"><span class="comment">每个block大小为BLOCK_SIZE * BLOCK_SIZE</span></span><br><span class="line"><span class="comment">将矩阵A中对应此block的大小为BLOCK_SIZE * K的矩阵划分为BLOCK_SIZE * BLOCK_SIZE的小块,一共划分为K/BLOCK_SIZE(向上取整)块</span></span><br><span class="line"><span class="comment">将矩阵B中对应此block的大小为K * BLOCK_SIZE的矩阵划分为BLOCK_SIZE * BLOCK_SIZE的小块，一共划分为K/BLOCK_SIZE(向上取整)块</span></span><br><span class="line"><span class="comment">将A划分的第一块放入共享内存shared_A中，将B划分的第一块放入共享内存shared_B中，进行计算</span></span><br><span class="line"><span class="comment">接着第二块，第三块，....最后将结果相加      </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">matrixMultiply_use_sharedMemory</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> k,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y*blockDim.y + threadIdx.y;<span class="comment">//线程所在的行</span></span><br><span class="line">    <span class="type">int</span> col = blockIdx.x*blockDim.x + threadIdx.x;<span class="comment">//线程所在的列</span></span><br><span class="line">    <span class="comment">//定义共享内存</span></span><br><span class="line">    __shared__ <span class="type">float</span> shared_A[BLOCK_SIZE][BLOCK_SIZE];</span><br><span class="line">    __shared__ <span class="type">float</span> shared_B[BLOCK_SIZE][BLOCK_SIZE];</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 循环计算A划分的每一块与B划分的每一块的乘积</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;(k<span class="number">-1</span>)/BLOCK_SIZE+<span class="number">1</span>; i++){</span><br><span class="line">        <span class="comment">// 将A划分的第i块放入共享内存shared_A中</span></span><br><span class="line">        <span class="comment">// 当此线程对应的行超出矩阵A的行数时，（row&gt;m）</span></span><br><span class="line">        <span class="comment">// 以及第i个块中列超出A的列范围时（i * BLOCK_SIZE + threadIdx.x&gt;k），</span></span><br><span class="line">        <span class="comment">// 将共享内存中对应的元素置为0</span></span><br><span class="line">        <span class="keyword">if</span>(i * BLOCK_SIZE + threadIdx.x &lt; k &amp;&amp; row &lt; m){</span><br><span class="line">            shared_A[threadIdx.y][threadIdx.x] = array_A[row * k + i * BLOCK_SIZE + threadIdx.x];</span><br><span class="line">        }<span class="keyword">else</span>{</span><br><span class="line">            shared_A[threadIdx.y][threadIdx.x] = <span class="number">0.0</span>;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将B划分的第i块放入共享内存shared_B中</span></span><br><span class="line">        <span class="keyword">if</span>(i * BLOCK_SIZE + threadIdx.y&lt;k &amp;&amp; col &lt; n){</span><br><span class="line">            shared_B[threadIdx.y][threadIdx.x] = array_B[(i * BLOCK_SIZE + threadIdx.y) * n + col];</span><br><span class="line">        }<span class="keyword">else</span>{</span><br><span class="line">            shared_B[threadIdx.y][threadIdx.x] = <span class="number">0.0</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 等待所有线程将数据加载到共享内存中</span></span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算结果</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>; j&lt;BLOCK_SIZE; j++){</span><br><span class="line">            <span class="comment">// array_C[row * n + col] += shared_A[threadIdx.y][j] * shared_B[j][threadIdx.x];</span></span><br><span class="line">            sum += shared_A[threadIdx.y][j] * shared_B[j][threadIdx.x];</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 等待所有线程计算完毕</span></span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将结果保存到矩阵C中 这里必须保证row和col都在矩阵C的范围内</span></span><br><span class="line">        <span class="keyword">if</span>(row &lt; m &amp;&amp; col &lt; n){</span><br><span class="line">            array_C[row * n + col] = sum;</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="三、使用cublas库进行矩阵乘法"><a href="#三、使用cublas库进行矩阵乘法" class="headerlink" title="三、使用cublas库进行矩阵乘法"></a>三、使用cublas库进行矩阵乘法</h3><p>cublasSgemm 计算的计算公式：C=alpha* op(A) op(B)+beta*C</p>
<p>这里的op(A)由cublasSgemm 第二个参数决定，<strong>CUBLAS_OP_N</strong>： op(A) = A ，<strong>CUBLAS_OP_T</strong>： op(A) = <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.011ex" height="1.904ex" role="img" focusable="false" viewBox="0 -841.7 1330.8 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container>(转置)</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cublasSgemm</span>(cublasHandle_t handle,<span class="comment">//句柄</span></span><br><span class="line">            cublasOperation_t transa, <span class="comment">//是否对第一个矩阵转置</span></span><br><span class="line">            cublasOperation_t transb, <span class="comment">//是否对第二个矩阵转置</span></span><br><span class="line">            <span class="type">int</span> m, <span class="comment">//第一矩阵的行数</span></span><br><span class="line">            <span class="type">int</span> n, <span class="comment">// 第二个矩阵的列数</span></span><br><span class="line">            <span class="type">int</span> k, <span class="comment">// 第一个矩阵的列数</span></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> *alpha, <span class="comment">// 乘法系数</span></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> *A, <span class="comment">// 第一个矩阵的指针</span></span><br><span class="line">            <span class="type">int</span> lda, <span class="comment">//第一个矩阵的主维 如果不转置就是当前等效矩阵的行数，如果设置为转置就是列数</span></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> *B,<span class="comment">//第一个矩阵的指针,和上面相同</span></span><br><span class="line">            <span class="type">int</span> ldb,</span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> *beta, <span class="comment">//加法系数</span></span><br><span class="line">            <span class="type">float</span> *C, </span><br><span class="line">            <span class="type">int</span> ldc</span><br><span class="line">           );</span><br></pre></td></tr></table></figure></div>

<p><strong>注意：</strong> cublas不同于C++，是列优先存储。如果我们直接将我们的矩阵A、B输入进去，这里会计算 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.011ex" height="1.904ex" role="img" focusable="false" viewBox="0 -841.7 1330.8 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container> *  <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.031ex" height="1.904ex" role="img" focusable="false" viewBox="0 -841.7 1339.8 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(792,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container>。如果我们要计算A<em>B = C， 我们将第一个矩阵传入B，第二个矩阵传入A。此时cublas会计算  <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.031ex" height="1.904ex" role="img" focusable="false" viewBox="0 -841.7 1339.8 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(792,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container> *  <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.011ex" height="1.904ex" role="img" focusable="false" viewBox="0 -841.7 1330.8 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container>  =  $(A</em>B)^T<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="1.76ex" height="1.505ex" role="img" focusable="false" viewBox="0 -583 778 665"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g></g></svg></mjx-container>C^T<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="6.787ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">时</text></g></g></g></svg></mjx-container>C^T<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="75.77ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 33490.4 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">在</text></g><g data-mml-node="mi" transform="translate(1000,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(1433,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2005,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(2434,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2732,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3261,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(3730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">同</text></g><g data-mml-node="mi" transform="translate(4730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">样</text></g><g data-mml-node="mi" transform="translate(5730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">是</text></g><g data-mml-node="mi" transform="translate(6730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">按</text></g><g data-mml-node="mi" transform="translate(7730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">列</text></g><g data-mml-node="mi" transform="translate(8730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">优</text></g><g data-mml-node="mi" transform="translate(9730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">先</text></g><g data-mml-node="mi" transform="translate(10730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">存</text></g><g data-mml-node="mi" transform="translate(11730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">储</text></g><g data-mml-node="mi" transform="translate(12730,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(13730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">但</text></g><g data-mml-node="mi" transform="translate(14730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">我</text></g><g data-mml-node="mi" transform="translate(15730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">们</text></g><g data-mml-node="mi" transform="translate(16730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">使</text></g><g data-mml-node="mi" transform="translate(17730,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">用</text></g><g data-mml-node="mi" transform="translate(18730,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(19712.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(20712.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(21490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(22490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">按</text></g><g data-mml-node="mi" transform="translate(23490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">行</text></g><g data-mml-node="mi" transform="translate(24490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">优</text></g><g data-mml-node="mi" transform="translate(25490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">先</text></g><g data-mml-node="mi" transform="translate(26490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">打</text></g><g data-mml-node="mi" transform="translate(27490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">印</text></g><g data-mml-node="mi" transform="translate(28490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">出</text></g><g data-mml-node="mi" transform="translate(29490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">矩</text></g><g data-mml-node="mi" transform="translate(30490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">阵</text></g><g data-mml-node="mi" transform="translate(31490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">就</text></g><g data-mml-node="mi" transform="translate(32490.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">是</text></g></g></g></svg></mjx-container>C^T$的转置 ，也就是我们最终的结果C。<strong>注意函数参数中mnk的值</strong>。</p>
<p><strong>关于m、n、k以及lda、ldb参数</strong>：</p>
<p>只需要看最终计算的矩阵op（A） * op（B）的大小决定<strong>（不用管有没有转置，按行还是按列）</strong>。</p>
<p>例如：A（4*2）、B（4 * 2） 传入cublasSgemm(CUBLAS_OP_N,CUBLAS_OP_T,  A，B ) ，这里A本来按行优先这里没有转置进去后就变成</p>
<p> <strong>op（A） = <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.011ex" height="1.904ex" role="img" focusable="false" viewBox="0 -841.7 1330.8 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container>   、op(B) = B</strong></p>
<p>m：op(A)的行数</p>
<p>n： op(B)的列数</p>
<p>k：op（A）的列数</p>
<p>lda：如果设置了<strong>CUBLAS_OP_N</strong> 就是op（A）的行数，<strong>CUBLAS_OP_T</strong> 就是op（A）的列数</p>
<p>ldb：如果设置了<strong>CUBLAS_OP_N</strong> 就是op（B）的行数，<strong>CUBLAS_OP_T</strong> 就是op（B）的列数</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">General Matrix Multiplication</span></span><br><span class="line"><span class="comment">cublas实现通用矩阵乘法</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// inculde上一级目录的common.cuh文件  该文件中包含setGPU()函数</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"../common.cuh"</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span><span class="comment">//包含cuda运行时的头文件</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cublas_v2.h&gt;</span><span class="comment">//包含cublas运行时的头文件</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std; <span class="comment">//使用标准命名空间</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 3000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> K 2000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 2000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 16 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span> *array, <span class="type">int</span> size)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;size;i++){</span><br><span class="line">        array[i] = <span class="built_in">rand</span>() % <span class="number">10</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMatrix</span><span class="params">(<span class="type">float</span> *array,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            cout&lt;&lt;array[i * n + j]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">        }</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">//setGPU(0);</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//1.定义cublas句柄</span></span><br><span class="line">    cublasHandle_t handle;</span><br><span class="line">    cublasStatus_t  status = <span class="built_in">cublasCreate</span>(&amp;handle);</span><br><span class="line">    <span class="comment">//检测cubals是否创建成功</span></span><br><span class="line">    <span class="keyword">if</span> (status != CUBLAS_STATUS_SUCCESS)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (status == CUBLAS_STATUS_NOT_INITIALIZED) {</span><br><span class="line">            cout &lt;&lt; <span class="string">"CUBLAS 对象实例化出错"</span> &lt;&lt; endl;</span><br><span class="line">        }</span><br><span class="line">        <span class="built_in">getchar</span> ();</span><br><span class="line">        <span class="keyword">return</span> EXIT_FAILURE;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义矩阵 矩阵是连续的一维数组 按照行优先存储</span></span><br><span class="line">    <span class="type">float</span> *array_A,*array_B,*array_C,*array_C_host; </span><br><span class="line">    <span class="type">float</span> *d_arrayA,*d_arrayB,*d_arrayC;</span><br><span class="line">    <span class="type">int</span> size_A = M * K * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = K * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = M * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    array_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    array_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    array_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    array_C_host = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    <span class="comment">//初始化矩阵</span></span><br><span class="line">    <span class="built_in">initial</span>(array_A,M * K);</span><br><span class="line">    <span class="built_in">initial</span>(array_B,K * N);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayA,size_A);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayB,size_B);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayC,size_C);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayA,array_A,size_A,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayB,array_B,size_B,cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.使用cublas实现矩阵乘法</span></span><br><span class="line">    <span class="type">float</span> alpha = <span class="number">1.0</span>;</span><br><span class="line">    <span class="type">float</span> beta = <span class="number">0.0</span>;</span><br><span class="line">    <span class="comment">// 这里B变成B的转置 （N*K）  A变成A转置 （K*M）</span></span><br><span class="line">    <span class="comment">// N, M, K分别对应 A行数、B列数、A列数</span></span><br><span class="line">    <span class="built_in">cublasSgemm</span>(handle, CUBLAS_OP_N, CUBLAS_OP_N, N, M, K, &amp;alpha, d_arrayB, N, d_arrayA, K, &amp;beta, d_arrayC, N);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(array_C,d_arrayC,size_C,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    cout&lt;&lt;<span class="string">"array_A:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_A,M,K);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_B:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_B,K,N);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_C:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_C,M,N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayA);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayB);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayC);</span><br><span class="line">    <span class="built_in">free</span>(array_A);</span><br><span class="line">    <span class="built_in">free</span>(array_B);</span><br><span class="line">    <span class="built_in">free</span>(array_C);</span><br><span class="line">    <span class="built_in">free</span>(array_C_host);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.销毁cublas句柄</span></span><br><span class="line">    <span class="built_in">cublasDestroy</span>(handle);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<p><strong>编译</strong></p>
<p>需要使用 <strong>-lcublas</strong> 链接库</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc cublas_GEMM.cu -o cublas_GEMM -lcublas</span><br></pre></td></tr></table></figure></div>



<h3 id="四、main函数"><a href="#四、main函数" class="headerlink" title="四、main函数"></a>四、main函数</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 打印矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMatrix</span><span class="params">(<span class="type">float</span> *array,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            cout&lt;&lt;array[i * n + j]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">        }</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">//setGPU(0);</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line">    <span class="comment">//定义矩阵 矩阵是连续的一维数组 按照行优先存储</span></span><br><span class="line">    <span class="type">float</span> *array_A,*array_B,*array_C,*array_C_host; </span><br><span class="line">    <span class="type">float</span> *d_arrayA,*d_arrayB,*d_arrayC;</span><br><span class="line">    <span class="type">int</span> size_A = M * K * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = K * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = M * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    array_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    array_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    array_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    array_C_host = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    <span class="comment">//初始化矩阵</span></span><br><span class="line">    <span class="built_in">initial</span>(array_A,M * K,<span class="number">2</span>);</span><br><span class="line">    <span class="built_in">initial</span>(array_B,K * N,<span class="number">2</span>);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayA,size_A);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayB,size_B);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayC,size_C);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayA,array_A,size_A,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayB,array_B,size_B,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="function">dim3 <span class="title">dimBlock</span><span class="params">(BLOCK_SIZE,BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">dimGrid</span><span class="params">((N - <span class="number">1</span>)/ dimBlock.x + <span class="number">1</span>,(M - <span class="number">1</span>) / dimBlock.y + <span class="number">1</span>)</span></span>;<span class="comment">//向上取整</span></span><br><span class="line">    matrixMultiply_use_sharedMemory&lt;&lt;&lt;dimGrid,dimBlock&gt;&gt;&gt;(d_arrayA,d_arrayB,d_arrayC,M,K,N);</span><br><span class="line">    <span class="comment">// matrixMultiply&lt;&lt;&lt;dimGrid,dimBlock&gt;&gt;&gt;(d_arrayA,d_arrayB,d_arrayC,M,K,N);</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(array_C,d_arrayC,size_C,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printMatrix</span>(array_C,M,N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayA);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayB);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayC);</span><br><span class="line">    <span class="built_in">free</span>(array_A);</span><br><span class="line">    <span class="built_in">free</span>(array_B);</span><br><span class="line">    <span class="built_in">free</span>(array_C);</span><br><span class="line">    <span class="built_in">free</span>(array_C_host);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h2 id="矩阵转置"><a href="#矩阵转置" class="headerlink" title="矩阵转置"></a>矩阵转置</h2><h3 id="一、直接转置"><a href="#一、直接转置" class="headerlink" title="一、直接转置"></a>一、直接转置</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">cuda实现矩阵转置  </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// inculde上一级目录的common.cuh文件  该文件中包含setGPU()函数</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"../common.cuh"</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span><span class="comment">//包含cuda运行时的头文件</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cublas_v2.h&gt;</span><span class="comment">//包含cublas运行时的头文件</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std; <span class="comment">//使用标准命名空间</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 50</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 40</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span> *array, <span class="type">int</span> size)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;size;i++){</span><br><span class="line">        array[i] = <span class="built_in">rand</span>() % <span class="number">10</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMatrix</span><span class="params">(<span class="type">float</span> *array,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            cout&lt;&lt;array[i * n + j]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">        }</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">矩阵转置</span></span><br><span class="line"><span class="comment">array_A:输入矩阵</span></span><br><span class="line"><span class="comment">array_B:输出矩阵</span></span><br><span class="line"><span class="comment">m:输入矩阵的行数</span></span><br><span class="line"><span class="comment">n:输入矩阵的列数</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">matrixTranspose</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">int</span> m, <span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里row和col对应输入矩阵的行和列</span></span><br><span class="line">    <span class="keyword">if</span>(row &lt; m &amp;&amp; col &lt; n){</span><br><span class="line">        array_B[col * m + row] = array_A[row * n + col];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">//setGPU(0);</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义矩阵 矩阵是连续的一维数组 按照行优先存储</span></span><br><span class="line">    <span class="type">float</span> *array_A,*array_B; </span><br><span class="line">    <span class="type">float</span> *d_arrayA,*d_arrayB;</span><br><span class="line">    <span class="type">int</span> size_A = M * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = N * M * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    array_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    array_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_B);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//初始化矩阵</span></span><br><span class="line">    <span class="built_in">initial</span>(array_A,M * N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayA,size_A);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayB,size_B);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayA,array_A,size_A,cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义block和grid的维度</span></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">16</span>,<span class="number">16</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">((N + block.x - <span class="number">1</span>) / block.x,(M + block.y - <span class="number">1</span>) / block.y)</span></span>;</span><br><span class="line"></span><br><span class="line">    matrixTranspose&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_arrayA,d_arrayB,M,N);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(array_B,d_arrayB,size_B,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    cout&lt;&lt;<span class="string">"array_A:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_A,M,N);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_B:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_B,N,M);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayA);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayB);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">free</span>(array_A);</span><br><span class="line">    <span class="built_in">free</span>(array_B);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="二、使用共享内存-1"><a href="#二、使用共享内存-1" class="headerlink" title="二、使用共享内存"></a>二、使用共享内存</h3><p>在直接转置的核函数中，相邻的线程访问B中的数据是连续的，但访问A时不连续，而这种不对齐、不可合并的写操作将导致较大的访存开销。</p>
<p>使用<strong>共享内存</strong>，在同一个block中先将线程对应A中数据读入共享内存。再使用B的索引读取共享内存中的数据，但此时访问的共享内存是按照列索引会产生bank conflict。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">使用共享内存实现矩阵转置</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">matrixTransposeShared</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">int</span> m, <span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    __shared__ <span class="type">float</span> shared_A[<span class="number">16</span>][<span class="number">16</span>];</span><br><span class="line">    <span class="comment">// 矩阵A的元素复制到共享内存中</span></span><br><span class="line">    <span class="keyword">if</span>(row &lt; m &amp;&amp; col &lt; n){</span><br><span class="line">        shared_A[threadIdx.y][threadIdx.x] = array_A[row * n + col];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算矩阵B的索引</span></span><br><span class="line">    row = blockIdx.x * blockDim.x + threadIdx.y;</span><br><span class="line">    col = blockIdx.y * blockDim.y + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里访问矩阵B是连续的 但是访问shared_A是按列访问的会产生bank conflict</span></span><br><span class="line">    <span class="keyword">if</span>(row &lt; n &amp;&amp; col &lt; m){</span><br><span class="line">        array_B[row * m + col] = shared_A[threadIdx.x][threadIdx.y];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="三、解决bank-coflict"><a href="#三、解决bank-coflict" class="headerlink" title="三、解决bank coflict"></a>三、解决bank coflict</h3><p>这里因为正好相邻线程访问到同一个bank，此时我们将shared_A多加入一列，此时shared_A在bank的存储会错开一位避免bank conflict。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">使用共享内存实现矩阵转置 优化bank conflict</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">matrixTransposeShared_withoutbc</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">int</span> m, <span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//使用padding的方式解决bank conflict</span></span><br><span class="line">    __shared__ <span class="type">float</span> shared_A[<span class="number">16</span>][<span class="number">16</span>+<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 矩阵A的元素复制到共享内存中</span></span><br><span class="line">    <span class="keyword">if</span>(row &lt; m &amp;&amp; col &lt; n){</span><br><span class="line">        shared_A[threadIdx.y][threadIdx.x] = array_A[row * n + col];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算矩阵B的索引</span></span><br><span class="line">    row = blockIdx.x * blockDim.x + threadIdx.y;</span><br><span class="line">    col = blockIdx.y * blockDim.y + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里访问矩阵B是连续的 但是访问shared_A是按列访问的会产生bank conflict</span></span><br><span class="line">    <span class="keyword">if</span>(row &lt; n &amp;&amp; col &lt; m){</span><br><span class="line">        array_B[row * m + col] = shared_A[threadIdx.x][threadIdx.y];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><h3 id="一维卷积"><a href="#一维卷积" class="headerlink" title="一维卷积"></a>一维卷积</h3><h4 id="一、补零处理边界"><a href="#一、补零处理边界" class="headerlink" title="一、补零处理边界"></a>一、补零处理边界</h4><p>数组A长度为m，卷积核B长度为n，自动对A两端补零，最后卷积的结果C长度为m。</p>
<p>使用m个线程处理C中对应的数据。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">convolution_1d</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> half = n / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">        <span class="comment">//卷积核的中心对齐到矩阵A的第i个元素 </span></span><br><span class="line">        <span class="comment">//使用if条件处理边界问题 对于两端补零的情况直接省略不去计算</span></span><br><span class="line">        <span class="keyword">if</span>(i + j - half&gt;=<span class="number">0</span> &amp;&amp; i + j - half&lt;m){</span><br><span class="line">            sum += array_A[i + j - half] * array_B[j];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    array_C[i] = sum;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h4 id="二、使用常量内存"><a href="#二、使用常量内存" class="headerlink" title="二、使用常量内存"></a>二、使用常量内存</h4><p>对于核函数，其长度一般不会太长。并且每一个线程都会调用相同的核函数。</p>
<p>虽然常数存储器的实现也是DRAM，但是CUDA运行时系统知道常数存储器变量不会改变，所以会将其直接放入高速缓存中。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明常量 这里需要在使用之前声明 否则编译会报错</span></span><br><span class="line">__constant__ <span class="type">float</span> const_array_B[N];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一维卷积 </span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">convolution_1d</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> half = n / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">        <span class="comment">//卷积核的中心对齐到矩阵A的第i个元素 </span></span><br><span class="line">        <span class="comment">//使用if条件处理边界问题 对于两端补零的情况直接省略不去计算</span></span><br><span class="line">        <span class="keyword">if</span>(i + j - half&gt;=<span class="number">0</span> &amp;&amp; i + j - half&lt;m){</span><br><span class="line">            sum += array_A[i + j - half] * const_array_B[j];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    array_C[i] = sum;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">// 将array_B的值赋给 const_array_B</span></span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(const_array_B,array_B,size_B);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//一维卷积</span></span><br><span class="line">    convolution_1d&lt;&lt;&lt;<span class="number">1</span>,M&gt;&gt;&gt;(d_arrayA,d_arrayC,M,N);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h4 id="三、分块卷积使用共享内存"><a href="#三、分块卷积使用共享内存" class="headerlink" title="三、分块卷积使用共享内存"></a>三、分块卷积使用共享内存</h4><p>在读取A中的数据时，A中的每个数据都要被读取n次（卷积核的长度）。使用共享内存可以加快数据的读取次数。</p>
<p>我们将block的大小设置为block_size, 这block_size个数据进行卷积计算时会用到其本身和前后n/2个数据。</p>
<p>所以我们在一个block中需要将 n/2 + block_size + n/2 (= block_size + n -1)个数据加载到shared memory。</p>
<p>其中中间的block_size 的对应元素称为内部元素。</p>
<p>前后n/2个元素称为光环元素（halo element）或边缘元素（skirt element）。</p>
<p>读取前n/2个数据时，这n/2个数据实际上是上一个block中线程对应的数据中的最后n/2个。此时我们使用次block中的后n/2个线程的id再减去一个block_size来找到其在A中索引。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> halo_index_left = (blockIdx.x - <span class="number">1</span>) * blockDim.x + threadIdx.x;<span class="comment">//左侧halo元素对应在A中的索引</span></span><br><span class="line"><span class="keyword">if</span>(threadId.x &gt;= blockDim.x - n/<span class="number">2</span>){<span class="comment">//对后n/2个线程进行操作</span></span><br><span class="line">	shared_A[threadId.x - （blockDim.x - n/<span class="number">2</span>)] = <span class="comment">//共享内存对应的索引从0~（n/2-1） </span></span><br><span class="line">		(halo_index_left &lt; <span class="number">0</span>)?<span class="number">0</span>:A[halo_index_left];<span class="comment">// 边界补零</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<p>读取中间线程对应的block_size个数据</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shared_A[n/<span class="number">2</span>+threadIdx.x] = N[blockIdx.x*blockDim.x + threadIdx.x];</span><br></pre></td></tr></table></figure></div>



<p>读取后n/2个数据时，使用前n/2个线程读取，过程同上。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> halo_index_right = (blockIdx.x + <span class="number">1</span>) * blockDim.x + threadIdx.x;<span class="comment">//右侧halo元素对应在A中的索引</span></span><br><span class="line"><span class="keyword">if</span>(threadId.x &lt; n/<span class="number">2</span>){<span class="comment">//对前n/2个线程进行操作</span></span><br><span class="line">	shared_A[threadId.x + blockDim.x + n/<span class="number">2</span>] = <span class="comment">//共享内存对应的索引从block_size + n/2~ block_size + n-1</span></span><br><span class="line">		(halo_index_left &gt; m)?<span class="number">0</span>:A[halo_index_right];<span class="comment">// 边界补零</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<p>代码</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">cuda实现一维卷积 使用常量内存+共享内存</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// inculde上一级目录的common.cuh文件  该文件中包含setGPU()函数</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"../common.cuh"</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std; <span class="comment">//使用标准命名空间</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 1000<span class="comment">//矩阵A的长度</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 23<span class="comment">//卷积核的长度</span></span></span><br><span class="line"></span><br><span class="line">__constant__ <span class="type">float</span> const_array_B[N];</span><br><span class="line"></span><br><span class="line"><span class="comment">// Warmup</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">warmup</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">float</span> f = <span class="built_in">sqrtf</span>((<span class="type">float</span>)idx);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span> *array, <span class="type">int</span> size)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;size;i++){</span><br><span class="line">        array[i] = <span class="built_in">rand</span>() % <span class="number">10</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMatrix</span><span class="params">(<span class="type">float</span> *array,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            cout&lt;&lt;array[i * n + j]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">        }</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一维卷积 </span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">convolution_1d</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> half = n / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> shared_A[];<span class="comment">//共享内存</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> halo_index_left = (blockIdx.x - <span class="number">1</span>) * blockDim.x + threadIdx.x;<span class="comment">//左侧halo元素对应在A中的索引</span></span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &gt;= blockDim.x - half){<span class="comment">//对后n/2个线程进行操作</span></span><br><span class="line">        shared_A[threadIdx.x - (blockDim.x - half)] = <span class="comment">//共享内存对应的索引从0~（n/2-1） </span></span><br><span class="line">            (halo_index_left &lt; <span class="number">0</span>)?<span class="number">0</span>:array_A[halo_index_left];<span class="comment">// 边界补零</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    shared_A[n/<span class="number">2</span>+threadIdx.x] = array_A[blockIdx.x*blockDim.x + threadIdx.x];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> halo_index_right = (blockIdx.x + <span class="number">1</span>) * blockDim.x + threadIdx.x;<span class="comment">//右侧halo元素对应在A中的索引</span></span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &lt; half){<span class="comment">//对前n/2个线程进行操作</span></span><br><span class="line">        shared_A[threadIdx.x + blockDim.x + half] = <span class="comment">//共享内存对应的索引从block_size + n/2~ block_size + n-1</span></span><br><span class="line">            (halo_index_left &gt; m)?<span class="number">0</span>:array_A[halo_index_right];<span class="comment">// 边界补零</span></span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            sum += shared_A[j+threadIdx.x] * const_array_B[j];</span><br><span class="line">    }</span><br><span class="line">    array_C[i] = sum;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">//setGPU(0);</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义矩阵 矩阵是连续的一维数组 按照行优先存储</span></span><br><span class="line">    <span class="type">float</span> *array_A,*array_B,*array_C; </span><br><span class="line">    <span class="type">float</span> *d_arrayA,*d_arrayB,*d_arrayC;</span><br><span class="line">    <span class="type">int</span> size_A = <span class="number">1</span> * M * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = <span class="number">1</span> * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = <span class="number">1</span> * M * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    array_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    array_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    array_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    <span class="comment">//初始化矩阵</span></span><br><span class="line">    <span class="built_in">initial</span>(array_A,<span class="number">1</span> * M);</span><br><span class="line">    <span class="built_in">initial</span>(array_B,<span class="number">1</span> * N);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayA,size_A);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayB,size_B);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayC,size_C);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayA,array_A,size_A,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="comment">// cudaMemcpy(d_arrayB,array_B,size_B,cudaMemcpyHostToDevice);</span></span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(const_array_B,array_B,size_B);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//warmup</span></span><br><span class="line">    warmup&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//一维卷积</span></span><br><span class="line">    <span class="function">dim3 <span class="title">block_size</span><span class="params">(<span class="number">32</span>,<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid_size</span><span class="params">((M + block_size.x - <span class="number">1</span>) / block_size.x,<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    convolution_1d&lt;&lt;&lt;grid_size,block_size,<span class="built_in">sizeof</span>(<span class="type">float</span>) *(block_size.x + N - <span class="number">1</span>)&gt;&gt;&gt;(d_arrayA,d_arrayC,M,N);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(array_C,d_arrayC,size_C,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    cout&lt;&lt;<span class="string">"array_A:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_A,<span class="number">1</span>,M);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_B:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_B,<span class="number">1</span>,N);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_C:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_C,<span class="number">1</span>,M);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayA);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayB);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayC);</span><br><span class="line">    <span class="built_in">free</span>(array_A);</span><br><span class="line">    <span class="built_in">free</span>(array_B);</span><br><span class="line">    <span class="built_in">free</span>(array_C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h3><p>仿照一维卷积，使用共享内存，将A中的值赋值到共享内存中。</p>
<p><strong>注意</strong>：最后赋值结果的时候需要判断线程位置是否超出输出矩阵C的范围。</p>
<p>线程块的大小为 block_size * block_size , 对应的共享内存矩阵大小应该为 （block_size+n-1） * （block_size+n-1）</p>
<p>将共享内存shared_A分为四块进行赋值。</p>
<p>先使用所有线程赋值shared_A左上角block_size * block_size范围的数值。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//操作共享内存 使用线程将共享内存左上角block_size * block_size的区域填充</span></span><br><span class="line"><span class="keyword">if</span>( row-half &lt; <span class="number">0</span> || row-half &gt;= m || col-half &lt; <span class="number">0</span> || col-half &gt;= m){</span><br><span class="line">    shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">}</span><br><span class="line"><span class="keyword">else</span>{</span><br><span class="line">    shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = array_A[(row-half) * m + col-half];<span class="comment">//将A中的元素拷贝到共享内存中</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>再使用线程的右侧部分去赋值填充shared_A的右侧。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//操作共享内存 使用线程将共享内存右侧block_size * n/2的区域填充</span></span><br><span class="line"><span class="keyword">if</span>(threadIdx.x &gt;= blockDim.x - <span class="number">2</span>*half){</span><br><span class="line">    <span class="keyword">if</span>( row-half &lt; <span class="number">0</span> || row-half &gt;= m || col+half &lt; <span class="number">0</span> || col+half &gt;= m ){</span><br><span class="line">        shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{</span><br><span class="line">        shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = array_A[(row-half) * m + col + half];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>接着使用线程的下部分去赋值填充shared_A的下端。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//操作共享内存 使用线程将共享内存下侧n/2 * block_size的区域填充</span></span><br><span class="line"><span class="keyword">if</span>(threadIdx.y &gt;= blockDim.y - <span class="number">2</span>*half){</span><br><span class="line">    <span class="keyword">if</span>(row+half &lt; <span class="number">0</span> || row+half &gt;= m || col-half &lt; <span class="number">0</span> || col-half &gt;= m){</span><br><span class="line">        shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{</span><br><span class="line">        shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = array_A[(row + half) * m + col - half];</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>最后使用线程的右下角来填充shared_A的右下角。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(threadIdx.x &gt;= blockDim.x - <span class="number">2</span>*half &amp;&amp; threadIdx.y &gt;= blockDim.y - <span class="number">2</span>*half){</span><br><span class="line">    <span class="keyword">if</span>(row+half &lt; <span class="number">0</span> || row+half &gt;= m || col+half &lt; <span class="number">0</span> || col+half &gt;= m){</span><br><span class="line">        shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{</span><br><span class="line">        shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = array_A[(row + half) * m + col + half];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<p><strong>代码：</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">cuda实现二维卷积 使用常量内存+共享内存</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// inculde上一级目录的common.cuh文件  该文件中包含setGPU()函数</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"../common.cuh"</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std; <span class="comment">//使用标准命名空间</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 10<span class="comment">//矩阵A的长度</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 3<span class="comment">//卷积核的长度</span></span></span><br><span class="line"></span><br><span class="line">__constant__ <span class="type">float</span> const_array_B[N][N];</span><br><span class="line"></span><br><span class="line"><span class="comment">// Warmup</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">warmup</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">float</span> f = <span class="built_in">sqrtf</span>((<span class="type">float</span>)idx);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span> *array, <span class="type">int</span> size)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;size;i++){</span><br><span class="line">        array[i] = <span class="built_in">rand</span>() % <span class="number">10</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印矩阵</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMatrix</span><span class="params">(<span class="type">float</span> *array,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            cout&lt;&lt;array[i * n + j]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">        }</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 二维卷积  使用共享内存</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">convolution_2d_shared</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> half = n / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">float</span> shared_A[];<span class="comment">//共享内存</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//操作共享内存 使用线程将共享内存左上角block_size * block_size的区域填充</span></span><br><span class="line">    <span class="keyword">if</span>( row-half &lt; <span class="number">0</span> || row-half &gt;= m || col-half &lt; <span class="number">0</span> || col-half &gt;= m){</span><br><span class="line">        shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{</span><br><span class="line">        shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = array_A[(row-half) * m + col-half];<span class="comment">//将A中的元素拷贝到共享内存中</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">//操作共享内存 使用线程将共享内存右侧block_size * n/2的区域填充</span></span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &gt;= blockDim.x - <span class="number">2</span>*half){</span><br><span class="line">        <span class="keyword">if</span>( row-half &lt; <span class="number">0</span> || row-half &gt;= m || col+half &lt; <span class="number">0</span> || col+half &gt;= m ){</span><br><span class="line">            shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = <span class="number">0</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span>{</span><br><span class="line">            shared_A[threadIdx.y * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = array_A[(row-half) * m + col + half];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">//操作共享内存 使用线程将共享内存下侧n/2 * block_size的区域填充</span></span><br><span class="line">    <span class="keyword">if</span>(threadIdx.y &gt;= blockDim.y - <span class="number">2</span>*half){</span><br><span class="line">        <span class="keyword">if</span>(row+half &lt; <span class="number">0</span> || row+half &gt;= m || col-half &lt; <span class="number">0</span> || col-half &gt;= m){</span><br><span class="line">            shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span>{</span><br><span class="line">            shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x] = array_A[(row + half) * m + col - half];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &gt;= blockDim.x - <span class="number">2</span>*half &amp;&amp; threadIdx.y &gt;= blockDim.y - <span class="number">2</span>*half){</span><br><span class="line">        <span class="keyword">if</span>(row+half &lt; <span class="number">0</span> || row+half &gt;= m || col+half &lt; <span class="number">0</span> || col+half &gt;= m){</span><br><span class="line">            shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = <span class="number">0</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span>{</span><br><span class="line">            shared_A[(threadIdx.y + <span class="number">2</span>*half) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + <span class="number">2</span>*half] = array_A[(row + half) * m + col + half];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            sum += shared_A[(threadIdx.y + i) * (blockDim.x+n<span class="number">-1</span>) + threadIdx.x + j] * const_array_B[i][j];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">//线程块中超过m * m的线程不进行赋值</span></span><br><span class="line">    <span class="keyword">if</span>(row &gt;= m || col &gt;= m){</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    }<span class="keyword">else</span>{</span><br><span class="line">        array_C[row * m + col] = sum;</span><br><span class="line">    }</span><br><span class="line">   </span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 二维卷积</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">convolution_2d</span><span class="params">(<span class="type">float</span> *array_A,<span class="type">float</span> *array_B,<span class="type">float</span> *array_C,<span class="type">int</span> m,<span class="type">int</span> n)</span></span>{</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> half = n / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++){</span><br><span class="line">            <span class="keyword">if</span>(row-half+i &lt; <span class="number">0</span> || row-half+i &gt;= m || col-half+j &lt; <span class="number">0</span> || col-half+j &gt;= m){</span><br><span class="line">                sum += <span class="number">0</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">else</span>{</span><br><span class="line">                sum += array_A[(row - half +i) * m + col-half+j] * array_B[i * n + j];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//线程块中超过m * m的线程不进行赋值</span></span><br><span class="line">    <span class="keyword">if</span>(row &gt;= m || col &gt;= m){</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    }<span class="keyword">else</span>{</span><br><span class="line">        array_C[row * m + col] = sum;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="comment">//setGPU(0);</span></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义矩阵 矩阵是连续的一维数组 按照行优先存储</span></span><br><span class="line">    <span class="type">float</span> *array_A,*array_B,*array_C,*array_C_2 ; </span><br><span class="line">    <span class="type">float</span> *d_arrayA,*d_arrayB,*d_arrayC,*d_arrayC_2;</span><br><span class="line">    <span class="type">int</span> size_A = M * M * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = N * N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = M * M * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    array_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    array_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    array_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    array_C_2 = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    <span class="comment">//初始化矩阵</span></span><br><span class="line">    <span class="built_in">initial</span>(array_A,M * M);</span><br><span class="line">    <span class="built_in">initial</span>(array_B,N * N);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayA,size_A);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayB,size_B);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayC,size_C);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arrayC_2,size_C);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayA,array_A,size_A,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arrayB,array_B,size_B,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(const_array_B,array_B,size_B);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//warmup</span></span><br><span class="line">    warmup&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//一维卷积</span></span><br><span class="line">    <span class="function">dim3 <span class="title">block_size</span><span class="params">(<span class="number">8</span>,<span class="number">8</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid_size</span><span class="params">((M + block_size.x - <span class="number">1</span>) / block_size.x,(M + block_size.y - <span class="number">1</span>) / block_size.y)</span></span>;</span><br><span class="line">    convolution_2d_shared&lt;&lt;&lt;grid_size,block_size,<span class="built_in">sizeof</span>(<span class="type">float</span>) *(block_size.x + N - <span class="number">1</span>)*(block_size.x + N - <span class="number">1</span>)&gt;&gt;&gt;(d_arrayA,d_arrayC,M,N);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    convolution_2d&lt;&lt;&lt;grid_size,block_size&gt;&gt;&gt;(d_arrayA,d_arrayB,d_arrayC_2,M,N);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(array_C_2,d_arrayC_2,size_C,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(array_C,d_arrayC,size_C,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印两个矩阵的差值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;M;i++){</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;M;j++){</span><br><span class="line">            <span class="keyword">if</span>(array_C[i * M + j] != array_C_2[i * M + j]){</span><br><span class="line">                cout&lt;&lt;<span class="string">"array_C["</span>&lt;&lt;i&lt;&lt;<span class="string">"]["</span>&lt;&lt;j&lt;&lt;<span class="string">"]:"</span>&lt;&lt;array_C[i * M + j]&lt;&lt;endl;</span><br><span class="line">                cout&lt;&lt;<span class="string">"array_C_2["</span>&lt;&lt;i&lt;&lt;<span class="string">"]["</span>&lt;&lt;j&lt;&lt;<span class="string">"]:"</span>&lt;&lt;array_C_2[i * M + j]&lt;&lt;endl;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    cout&lt;&lt;<span class="string">"array_A:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_A,M,M);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_B:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_B,N,N);</span><br><span class="line">    cout&lt;&lt;<span class="string">"array_C:"</span>&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">printMatrix</span>(array_C,M,M);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayA);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayB);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arrayC);</span><br><span class="line">    <span class="built_in">free</span>(array_A);</span><br><span class="line">    <span class="built_in">free</span>(array_B);</span><br><span class="line">    <span class="built_in">free</span>(array_C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h2 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h2><p>Prefix Sum（前缀和），也被称为Scan/Prefix Scan。</p>
<p>输入一个数组input[n]，计算新数组output[n], 使得对于任意元素output[i]都满足：</p>
<p>output[i] = input[0] + input[1] + … input[i]</p>
<h3 id="简单实现"><a href="#简单实现" class="headerlink" title="简单实现"></a>简单实现</h3><p>假设每个block中有32个线程，input为128个1。</p>
<p>我们使用每个block中的第一个线程来挨个计算这个block中的前缀和。</p>
<p>output变成：output[0] = 1,output[1] = 2……..output[31] = 32，<strong>下面接着是第二个block计算的结果</strong>： output[32] = 1 output[33] = 2………</p>
<p>再将最后一个线程的结果（也就是这个block中数据的总和）加入到一个在part中累加，</p>
<p>part[0] = 32, part[1] = 64, part[2] = 96</p>
<p>最后再将当前线程的数据全部加上part[bloakIdx -1]。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">cuda实现前缀和 </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// inculde上一级目录的common.cuh文件  该文件中包含setGPU()函数</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"../common.cuh"</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ScanAndWritePartSumKernel</span><span class="params">(<span class="type">const</span> <span class="type">int32_t</span>* input, <span class="type">int32_t</span>* part,                                                                                                                                                                                                 <span class="type">int32_t</span>* output, <span class="type">size_t</span> n,</span></span></span><br><span class="line"><span class="params"><span class="function">                                          <span class="type">size_t</span> part_num)</span> </span>{</span><br><span class="line">  <span class="type">size_t</span> part_i = blockIdx.x;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 读取input[part_begin:part_end]到共享内存中</span></span><br><span class="line">  <span class="keyword">extern</span> __shared__ <span class="type">int32_t</span> shm[];</span><br><span class="line">  <span class="type">size_t</span> index = part_i * blockDim.x + threadIdx.x;</span><br><span class="line">  shm[threadIdx.x] = index &lt; n ? input[index] : <span class="number">0</span>;</span><br><span class="line">  __syncthreads();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//计算每个线程的前缀和</span></span><br><span class="line">  <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) {  <span class="comment">// naive implemention</span></span><br><span class="line">    <span class="comment">// printf("gridDim.x = %d\n",gridDim.x);</span></span><br><span class="line">    <span class="type">int32_t</span> acc = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; blockDim.x; ++i) {</span><br><span class="line">      acc += shm[i];</span><br><span class="line">      shm[i] = acc;</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">  __syncthreads();</span><br><span class="line">  <span class="comment">//将共享内存中的数据写入output</span></span><br><span class="line">  <span class="keyword">if</span> (index &lt; n) {</span><br><span class="line">    output[index] = shm[threadIdx.x];</span><br><span class="line">  }</span><br><span class="line">  <span class="keyword">if</span> (threadIdx.x == blockDim.x - <span class="number">1</span>) {</span><br><span class="line">    part[part_i] = shm[threadIdx.x];</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ScanPartSumKernel</span><span class="params">(<span class="type">int32_t</span>* part, <span class="type">size_t</span> part_num)</span> </span>{</span><br><span class="line">  <span class="type">int32_t</span> acc = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; part_num; ++i) {</span><br><span class="line">    acc += part[i];</span><br><span class="line">    part[i] = acc;</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">AddBaseSumKernel</span><span class="params">(<span class="type">int32_t</span>* part, <span class="type">int32_t</span>* output, <span class="type">size_t</span> n,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">size_t</span> part_num)</span> </span>{</span><br><span class="line">  <span class="type">size_t</span> part_i = blockIdx.x;</span><br><span class="line">  <span class="keyword">if</span> (part_i != <span class="number">0</span>) {</span><br><span class="line">    <span class="type">int32_t</span> index = part_i * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; n) {</span><br><span class="line">      output[index] += part[part_i - <span class="number">1</span>];</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// for i in range(n):</span></span><br><span class="line"><span class="comment">//   output[i] = input[0] + input[1] + ... + input[i]</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ScanThenFan</span><span class="params">(<span class="type">const</span> <span class="type">int32_t</span>* input, <span class="type">int32_t</span>* buffer, <span class="type">int32_t</span>* output,</span></span></span><br><span class="line"><span class="params"><span class="function">                 <span class="type">size_t</span> n)</span> </span>{</span><br><span class="line">  <span class="type">size_t</span> part_size = <span class="number">1024</span>;  <span class="comment">// tuned</span></span><br><span class="line">  <span class="type">size_t</span> part_num = (n + part_size - <span class="number">1</span>) / part_size;</span><br><span class="line">  <span class="type">size_t</span> block_num = part_num;</span><br><span class="line">  <span class="comment">// use buffer[0:part_num] to save the metric of part</span></span><br><span class="line">  <span class="type">int32_t</span>* part = buffer;</span><br><span class="line">  <span class="comment">// after following step, part[i] = part_sum[i]</span></span><br><span class="line">  ScanAndWritePartSumKernel&lt;&lt;&lt;block_num, part_size,<span class="function">part_size* <span class="title">sizeof</span><span class="params">(<span class="type">int32_t</span>)</span>&gt;&gt;&gt;<span class="params">(input, part, output, n,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                      part_num)</span></span>;</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="comment">// after following step, part[i] = part_sum[0] + part_sum[1] + ... part_sum[i]</span></span><br><span class="line">  ScanPartSumKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(part, part_num);</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="comment">// make final result</span></span><br><span class="line">  AddBaseSumKernel&lt;&lt;&lt;block_num, part_size&gt;&gt;&gt;(part, output, n, part_num);</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">int32_t</span> *input, *output, *buffer;</span><br><span class="line">    <span class="type">int32_t</span> n = <span class="number">1000000</span>;</span><br><span class="line">    <span class="type">int32_t</span> threads = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int32_t</span> blocks = (n + threads - <span class="number">1</span>) / threads;</span><br><span class="line">    <span class="type">int32_t</span> size = n * <span class="built_in">sizeof</span>(<span class="type">int32_t</span>);</span><br><span class="line">    <span class="type">int32_t</span> buffer_size = blocks * <span class="built_in">sizeof</span>(<span class="type">int32_t</span>);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>(&amp;input, size);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>(&amp;output, size);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>(&amp;buffer, buffer_size);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//初始化input</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">        input[i] = <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="built_in">ScanThenFan</span>(input, buffer, output, n);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">      std::cout &lt;&lt; output[i] &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaFree</span>(input);</span><br><span class="line">    <span class="built_in">cudaFree</span>(output);</span><br><span class="line">    <span class="built_in">cudaFree</span>(buffer);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="warp优化"><a href="#warp优化" class="headerlink" title="warp优化"></a>warp优化</h3><p>在一个block中将线程按warp分，每个warp计算32个数据的前缀和，再将这32个数据总和写入warp_sum，然后继续将所有数据加上对应warp_sum。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ScanAndWritePartSumKernel</span><span class="params">(<span class="type">const</span> <span class="type">int32_t</span>* input, <span class="type">int32_t</span>* part,                                                                                           <span class="type">int32_t</span>* output, <span class="type">size_t</span> n,</span></span></span><br><span class="line"><span class="params"><span class="function">                                          <span class="type">size_t</span> part_num)</span> </span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">size_t</span> part_i = blockIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 读取input[part_begin:part_end]到共享内存中</span></span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int32_t</span> shm[];</span><br><span class="line">    <span class="type">size_t</span> index = part_i * blockDim.x + threadIdx.x;</span><br><span class="line">    shm[threadIdx.x] = index &lt; n ? input[index] : <span class="number">0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将1024个线程分为32个warp，每个warp中的第一个线程负责计算该warp中的前缀和</span></span><br><span class="line">    <span class="type">int</span> warp_id = threadIdx.x / <span class="number">32</span>;</span><br><span class="line">    __shared__ <span class="type">int32_t</span> warp_sum[<span class="number">32</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算每个warp中的前缀和</span></span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x%<span class="number">32</span>==<span class="number">0</span>) {  <span class="comment">// naive implemention</span></span><br><span class="line">        <span class="type">int32_t</span> acc = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i) {</span><br><span class="line">        acc += shm[i+<span class="number">32</span>*warp_id];</span><br><span class="line">        shm[i+<span class="number">32</span>*warp_id] = acc;</span><br><span class="line">        }</span><br><span class="line">        warp_sum[warp_id] = acc;</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将每个warp的前缀和相加</span></span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) {</span><br><span class="line">        <span class="type">int32_t</span> acc = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i) {</span><br><span class="line">        acc += warp_sum[i];</span><br><span class="line">        warp_sum[i] = acc;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将每个warp的前缀和加到该warp中的每个元素上</span></span><br><span class="line">    <span class="keyword">if</span> (warp_id &gt; <span class="number">0</span>) {</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i) {</span><br><span class="line">        shm[i+<span class="number">32</span>*warp_id] += warp_sum[warp_id - <span class="number">1</span>];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将共享内存中的数据写入output</span></span><br><span class="line">    <span class="keyword">if</span> (index &lt; n) {</span><br><span class="line">        output[index] = shm[threadIdx.x];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x == blockDim.x - <span class="number">1</span>) {</span><br><span class="line">        part[part_i] = shm[threadIdx.x];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>





<h2 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h2><p>softmax公式：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.27ex;" xmlns="http://www.w3.org/2000/svg" width="12.047ex" height="5.327ex" role="img" focusable="false" viewBox="0 -1351.5 5324.8 2354.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1094.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(2150.5,0)"><g data-mml-node="msup" transform="translate(994.8,676)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msup" transform="translate(1549.6,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></g><rect width="2934.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>当x过大时直接计算exp{x}会造成上溢，所以需要对x进行一次变换 <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="46.154ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 20400 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="Missing or unrecognized delimiter for \left" title="Missing or unrecognized delimiter for \left"><rect data-background="true" width="20400" height="950" y="-200"></rect><title>Missing or unrecognized delimiter for \left</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px">x_i = x_i - max _i\left{x_i\right}</text></g></g></g></g></svg></mjx-container> 。</p>
<p>所以softmax的计算分为三步：</p>
<ol>
<li>计算x中的最大值max，做max规约</li>
<li>计算所有的epx{x - max}的总和S，做sum规约</li>
<li>计算最终softmax，y = x/s.</li>
</ol>
<h4 id="max规约"><a href="#max规约" class="headerlink" title="max规约"></a>max规约</h4><p>参照reduce，使用shuffle操作，依次比较，使用max[i]来记录每个block中的最大值，最后在cpu中使用for循环找出全局最大值。</p>
<p>在cuda的设备函数中是由<strong>fmaxf</strong>函数来进行比较。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="comment">//__forceinline__修饰符是一个建议给编译器的指令，表示应尽可能将此函数内联到调用它的函数中。</span></span><br><span class="line"><span class="comment">// 内联函数可以减少函数调用的开销，但可能会增加生成的代码的大小</span></span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">float</span> <span class="title">warpReduceMax</span><span class="params">(<span class="type">float</span> max_data)</span> </span>{</span><br><span class="line">    <span class="comment">// printf("max_data = %f\n",max_data);</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>) max_data = <span class="built_in">fmaxf</span>(max_data, __shfl_down_sync(<span class="number">0xffffffff</span>, max_data, <span class="number">16</span>)); <span class="comment">// 0-16, 1-17, 2-18, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>) max_data = <span class="built_in">fmaxf</span>(max_data, __shfl_down_sync(<span class="number">0xffffffff</span>, max_data, <span class="number">8</span>));  <span class="comment">// 0-8, 1-9, 2-10, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>) max_data = <span class="built_in">fmaxf</span>(max_data, __shfl_down_sync(<span class="number">0xffffffff</span>, max_data, <span class="number">4</span>));   <span class="comment">// 0-4, 1-5, 2-6, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>) max_data = <span class="built_in">fmaxf</span>(max_data, __shfl_down_sync(<span class="number">0xffffffff</span>, max_data, <span class="number">2</span>));   <span class="comment">// 0-2, 1-3, 2-4, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>) max_data = <span class="built_in">fmaxf</span>(max_data, __shfl_down_sync(<span class="number">0xffffffff</span>, max_data, <span class="number">1</span>));   <span class="comment">// 0-1, 1-2, 2-3, etc.</span></span><br><span class="line">    <span class="comment">// printf("max_data = %f\n",max_data);</span></span><br><span class="line">    <span class="keyword">return</span> max_data;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">get_max2</span><span class="params">(<span class="type">float</span> *input,<span class="type">float</span> *d_max,<span class="type">int</span> size)</span></span>{</span><br><span class="line">    <span class="comment">// 通过规约的方式获取最大值</span></span><br><span class="line">    <span class="type">float</span> max_data = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(idx &lt; size){</span><br><span class="line">        max_data = input[idx];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{</span><br><span class="line">        max_data = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 用sdata存储每个warp的最大值</span></span><br><span class="line">    __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> laneId = threadIdx.x % <span class="number">32</span>;<span class="comment">//每个warps内的线程id</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> warpId = threadIdx.x / <span class="number">32</span>;<span class="comment">//每个warps块的id</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 每个warp内的线程进行规约</span></span><br><span class="line">    max_data = <span class="built_in">warpReduceMax</span>&lt;blockSize&gt;(max_data);</span><br><span class="line">    <span class="keyword">if</span>(idx == <span class="number">0</span>) <span class="built_in">printf</span>(<span class="string">"max_data = %f\n"</span>,max_data);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个warp内的第一个线程将最大值存储到sdata中</span></span><br><span class="line">    <span class="keyword">if</span> (laneId == <span class="number">0</span>) sdata[warpId] = max_data;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用第一个warp内的线程读取sdata中的数据</span></span><br><span class="line">    <span class="keyword">if</span> (warpId == <span class="number">0</span>) max_data = (threadIdx.x &lt; (blockDim.x / <span class="number">32</span>)) ? sdata[laneId] : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 第一个warp内的线程对sdata进行规约</span></span><br><span class="line">    <span class="keyword">if</span> (warpId == <span class="number">0</span>) max_data = <span class="built_in">warpReduceMax</span>&lt;blockSize/<span class="number">32</span>&gt;(max_data);   </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一个warp内的第一个线程将最大值存储到max_data中</span></span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) d_max[blockIdx.x] = max_data;</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h4 id="sum规约"><a href="#sum规约" class="headerlink" title="sum规约"></a>sum规约</h4><p>在读取x时顺便将做 x = epx{x - max}，然后参照reduce代码。</p>
<p>这里和max一样，使用sum[i]来存放每个block的总和，最后在cpu中用for循环计算全部总和。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">float</span> <span class="title">warpReduceSum</span><span class="params">(<span class="type">float</span> sum)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">16</span>); <span class="comment">// 0-16, 1-17, 2-18, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">8</span>);<span class="comment">// 0-8, 1-9, 2-10, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">4</span>);<span class="comment">// 0-4, 1-5, 2-6, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">2</span>);<span class="comment">// 0-2, 1-3, 4-6, 5-7, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>)sum += __shfl_down_sync(<span class="number">0xffffffff</span>, sum, <span class="number">1</span>);<span class="comment">// 0-1, 2-3, 4-5, etc.</span></span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduction</span><span class="params">(<span class="type">float</span> *A,<span class="type">float</span> * sum,<span class="type">int</span> N,<span class="type">float</span> *d_max)</span></span>{</span><br><span class="line">    <span class="comment">//每一个thread维护一个sum</span></span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// block内的线程id</span></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="comment">// grid中的线程id</span></span><br><span class="line">    <span class="type">int</span> global_id = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取全局内存到sum</span></span><br><span class="line">    <span class="keyword">if</span>(global_id &lt; N){</span><br><span class="line">        <span class="comment">// 这里直接计算 exp(A[i] - max)的sum</span></span><br><span class="line">        A[global_id] = <span class="built_in">expf</span>(A[global_id] - d_max[<span class="number">0</span>]);</span><br><span class="line">        sum = A[global_id];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">// A的数据不够block中的线程数时，将多余的线程对应的smem置为0</span></span><br><span class="line">        sum = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 用来存放每一个warp的结果</span></span><br><span class="line">    <span class="type">static</span> __shared__ <span class="type">float</span> warpLevelSums[<span class="number">32</span>]; <span class="comment">//最后使用一个warps来进行reduction操作</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> laneId = threadIdx.x % <span class="number">32</span>;<span class="comment">//每个warps内的线程id</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> warpId = threadIdx.x / <span class="number">32</span>;<span class="comment">//每个warps块的id</span></span><br><span class="line"></span><br><span class="line">    sum = <span class="built_in">warpReduceSum</span>&lt;blockSize&gt;(sum);<span class="comment">//每个warp内进行reduction操作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(laneId == <span class="number">0</span> )warpLevelSums[warpId] = sum;<span class="comment">//将每个warp的结果存放在warpLevelSums中</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用第一个warp来进行最后的规约 32个线程来读取warpLevelSums中的数据  将id大于warp块个数的summ置为0</span></span><br><span class="line">    sum = (threadIdx.x &lt; blockDim.x / <span class="number">32</span>) ? warpLevelSums[laneId] : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 最终的reduction操作</span></span><br><span class="line">    <span class="keyword">if</span> (warpId == <span class="number">0</span>) sum = <span class="built_in">warpReduceSum</span>&lt;blockSize/<span class="number">32</span>&gt;(sum);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果写回到全局内存</span></span><br><span class="line">    <span class="keyword">if</span>(tid == <span class="number">0</span>){</span><br><span class="line">        sum[blockIdx.x] = sum;</span><br><span class="line">    } </span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h4 id="softmax除法"><a href="#softmax除法" class="headerlink" title="softmax除法"></a>softmax除法</h4><p>最大值被存储在sum[0]中，对每一个input做除法，最后input中的值就是softmax的结果。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">soft_division</span><span class="params">(<span class="type">float</span>* input, <span class="type">float</span>* sum,<span class="type">int</span> N)</span></span>{</span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N) input[idx] = input[idx]/sum[<span class="number">0</span>];</span><br><span class="line">    __syncthreads();</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h4 id="cpu主函数"><a href="#cpu主函数" class="headerlink" title="cpu主函数"></a>cpu主函数</h4><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line"></span><br><span class="line">    <span class="built_in">setGPU</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//warmup</span></span><br><span class="line">    warmup&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义输入输出</span></span><br><span class="line">    <span class="type">int</span> size = <span class="number">10</span>;</span><br><span class="line">    <span class="type">float</span> *input = <span class="keyword">new</span> <span class="type">float</span>[size];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//初始化输入</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; size;i++){</span><br><span class="line">        input[i] = <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义输入输出在GPU上的内存</span></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">((size + block.x - <span class="number">1</span>) / block.x)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//用来存放每个block的最大值</span></span><br><span class="line">    <span class="type">float</span> *max = <span class="keyword">new</span> <span class="type">float</span>[grid.x];</span><br><span class="line">    <span class="comment">//存放每个block的sum</span></span><br><span class="line">    <span class="type">float</span> *sum = <span class="keyword">new</span> <span class="type">float</span>[grid.x];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *d_input;</span><br><span class="line">    <span class="type">float</span> *d_max;</span><br><span class="line">    <span class="type">float</span> *d_sum;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_input, size * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_max, grid.x * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_sum, grid.x * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//将输入拷贝到GPU</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_input,input,size * <span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.计算得到每个block的最大值</span></span><br><span class="line">    get_max2&lt;<span class="number">1024</span>&gt;&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_input,d_max,size);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(max,d_max,grid.x * <span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="comment">// 串行比较每个block的最大值 得到最大值存放在max[0]中</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt; grid.x;i++){</span><br><span class="line">        max[<span class="number">0</span>] = max[<span class="number">0</span>] &gt; max[i] ? max[<span class="number">0</span>] : max[i];</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 将最大值拷贝到GPU</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_max,max,grid.x * <span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2.计算每个block的sum 这里直接计算的是exp(A[i] - max)的sum</span></span><br><span class="line">    reduction&lt;<span class="number">1024</span>&gt;&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_input,d_sum,size,d_max);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(sum,d_sum,grid.x * <span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 串行计算最终的sum</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt; grid.x;i++){</span><br><span class="line">        sum[<span class="number">0</span>] += sum[i];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_sum,sum,grid.x * <span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 3.计算最终softmax </span></span><br><span class="line">    soft_division&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_input,d_sum,size);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(input,d_input,size * <span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印结果</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; size;i++){</span><br><span class="line">        cout &lt;&lt; input[i] &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] input;</span><br><span class="line">    <span class="keyword">delete</span>[] max;</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_input);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_max);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> cuda笔记</li>
        <li><strong>Author:</strong> Tong</li>
        <li><strong>Created at:</strong> 2024-01-15 15:03:12</li>
        
            <li>
                <strong>Updated at:</strong> 2024-08-15 14:48:01
            </li>
        
        <li>
            <strong>Link:</strong> https://github.com/Tong-Cao/Tong-Cao.github.io.git/2024/01/15/cuda笔记/
        </li>
        <li>
            <strong>License:</strong> This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.
        </li>
    </ul>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/cuda/">#cuda</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2024/01/27/FasterTransformer/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">FasterTransformer</span>
                                    <span class="post-nav-item">Prev posts</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/10/30/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">算法笔记</span>
                                    <span class="post-nav-item">Next posts</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
                <div class="comment-container">
                    <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-pjax>
        import { init } from 'https://evan.beee.top/js/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">cuda笔记</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA"><span class="nav-text">CUDA</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="nav-text">代码基本结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">线程模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B"><span class="nav-text">CUDA执行模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SM"><span class="nav-text">SM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cuda-Core"><span class="nav-text">Cuda Core</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#wrap"><span class="nav-text">wrap</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SM%E5%B9%B6%E8%A1%8C%E8%BF%90%E7%AE%97"><span class="nav-text">SM并行运算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA%E5%86%85%E5%AD%98"><span class="nav-text">CUDA内存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#register"><span class="nav-text">register</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#local-memory"><span class="nav-text">local memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#shared-memory"><span class="nav-text">shared memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#global-memory"><span class="nav-text">global memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#const-memory"><span class="nav-text">const memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%B9%E7%90%86%E5%86%85%E5%AD%98"><span class="nav-text">纹理内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU%E7%BC%93%E5%AD%98"><span class="nav-text">GPU缓存</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bank-conflict"><span class="nav-text">bank conflict</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7"><span class="nav-text">性能评价</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%8A%A0%E6%B3%95"><span class="nav-text">矩阵加法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%84%E7%BA%A6%E7%AE%97%E6%B3%95"><span class="nav-text">规约算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B8%8D%E8%BF%9E%E7%BB%AD%E8%A7%84%E7%BA%A6"><span class="nav-text">一、线程不连续规约</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E7%BA%BF%E7%A8%8B%E8%BF%9E%E7%BB%AD%E8%A7%84%E7%BA%A6"><span class="nav-text">二、线程连续规约</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E7%BA%BF%E7%A8%8B%E8%BF%9E%E7%BB%AD%E3%80%81%E5%86%85%E5%AD%98%E8%BF%9E%E7%BB%AD"><span class="nav-text">三、线程连续、内存连续</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E5%87%8F%E5%8D%8Ablock"><span class="nav-text">四、减半block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E5%87%8F%E5%B0%91%E5%90%8C%E6%AD%A5"><span class="nav-text">五、减少同步</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AD%E3%80%81%E5%BE%AA%E7%8E%AF%E5%AE%8C%E5%85%A8%E5%B1%95%E5%BC%80"><span class="nav-text">六、循环完全展开</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%83%E3%80%81shuffle%E6%93%8D%E4%BD%9C"><span class="nav-text">七、shuffle操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E6%9C%BA%E7%AB%AFmain%E5%87%BD%E6%95%B0"><span class="nav-text">主机端main函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="nav-text">矩阵乘法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%9B%B4%E6%8E%A5%E5%8A%A0%E8%BD%BD"><span class="nav-text">一、直接加载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="nav-text">二、使用共享内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E4%BD%BF%E7%94%A8cublas%E5%BA%93%E8%BF%9B%E8%A1%8C%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="nav-text">三、使用cublas库进行矩阵乘法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81main%E5%87%BD%E6%95%B0"><span class="nav-text">四、main函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE"><span class="nav-text">矩阵转置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%9B%B4%E6%8E%A5%E8%BD%AC%E7%BD%AE"><span class="nav-text">一、直接转置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98-1"><span class="nav-text">二、使用共享内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E8%A7%A3%E5%86%B3bank-coflict"><span class="nav-text">三、解决bank coflict</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF"><span class="nav-text">卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="nav-text">一维卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="nav-text">二维卷积</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E7%BC%80%E5%92%8C"><span class="nav-text">前缀和</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0"><span class="nav-text">简单实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#warp%E4%BC%98%E5%8C%96"><span class="nav-text">warp优化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax"><span class="nav-text">softmax</span></a></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2023</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Tong</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        VISITOR COUNT&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        TOTAL PAGE VIEWS&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a></span>
                <br>
            <span class="theme-version-container">THEME&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.1.3</a>
        </div>
        
        
        
            <div id="start_div" style="display:none">
                2023/4/30 12:00:00
            </div>
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    


</main>



<script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/utils.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/main.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/layouts/navbarShrink.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/tools/scrollTopBottom.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/tools/lightDarkSwitch.js"></script>




    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/tools/codeBlock.js"></script>



    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/layouts/lazyload.js"></script>



    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/tools/runtime.js"></script>
    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/layouts/odometer.min.js"></script>
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/assets/odometer-theme-minimal.css">



  <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/libs/Typed.min.js"></script>
  <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/plugins/typed.js"></script>







<div class="post-scripts pjax">
    
        <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/tools/tocToggle.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/libs/anime.min.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/layouts/toc.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/plugins/tabs.js"></script>
    
</div>


    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.3/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
